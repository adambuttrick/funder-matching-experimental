{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWn7ARvZ77Yi",
        "outputId": "11fa12b6-4e99-4b6c-e681-7ede34aed9e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.10/dist-packages (from flair) (1.34.23)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3.4)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.14)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from flair) (6.1.3)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.6.6)\n",
            "Requirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.20.2)\n",
            "Requirement already satisfied: janome>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.0)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.4)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.1.0)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.10/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2023.6.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.10/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.1)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (0.3.3)\n",
            "Requirement already satisfied: transformers[sentencepiece]<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.35.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (1.26.18)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.6.0)\n",
            "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flair) (3.0.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.23 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.34.23)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (0.1.99)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.14.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.11.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair) (6.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (23.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.4.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (3.20.3)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (0.26.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (5.9.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install flair\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zK7gBe38M9D",
        "outputId": "fb90a6a9-30d0-424d-92ec-4d03b5355fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, PooledFlairEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "import torch\n",
        "\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "label_type = 'ner'\n",
        "corpus = ColumnCorpus('/content/drive/MyDrive/training_data/flair/', columns)\n",
        "label_dictionary = corpus.make_label_dictionary(label_type=label_type)\n",
        "print(label_dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlzh8v0l8N4x",
        "outputId": "5776c572-da88-47b1-b558-badabb3e67f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-22 09:30:20,603 Reading data from /content/drive/MyDrive/training_data/flair\n",
            "2024-01-22 09:30:20,604 Train: /content/drive/MyDrive/training_data/flair/train.txt\n",
            "2024-01-22 09:30:20,605 Dev: None\n",
            "2024-01-22 09:30:20,607 Test: None\n",
            "2024-01-22 09:30:30,789 No test split found. Using 0% (i.e. 1402 samples) of the train split as test data\n",
            "2024-01-22 09:30:30,799 No dev split found. Using 0% (i.e. 1262 samples) of the train split as dev data\n",
            "2024-01-22 09:30:30,800 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "11355it [00:00, 31279.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-22 09:30:31,174 Dictionary created for label 'ner' with 2 values: ORG (seen 36268 times), AWARD (seen 28808 times)\n",
            "Dictionary with 2 tags: ORG, AWARD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_types = [\n",
        "    WordEmbeddings('glove'),\n",
        "    PooledFlairEmbeddings('news-forward', pooling='min'),\n",
        "    PooledFlairEmbeddings('news-backward', pooling='min'),\n",
        "]\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "tagger = SequenceTagger(hidden_size=256, embeddings=embeddings, tag_dictionary=label_dictionary, tag_type=label_type)\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "trainer.train('resources/taggers/example-ner', train_with_dev=True, max_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEhMey0kwJzY",
        "outputId": "e6dac36c-b519-488b-d812-09a11adef210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-22 09:30:42,945 SequenceTagger predicts: Dictionary with 9 tags: O, S-ORG, B-ORG, E-ORG, I-ORG, S-AWARD, B-AWARD, E-AWARD, I-AWARD\n",
            "2024-01-22 09:30:43,711 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,712 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): PooledFlairEmbeddings(\n",
            "      (context_embeddings): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.05, inplace=False)\n",
            "          (encoder): Embedding(300, 100)\n",
            "          (rnn): LSTM(100, 2048)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): PooledFlairEmbeddings(\n",
            "      (context_embeddings): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.05, inplace=False)\n",
            "          (encoder): Embedding(300, 100)\n",
            "          (rnn): LSTM(100, 2048)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=8292, out_features=8292, bias=True)\n",
            "  (rnn): LSTM(8292, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=11, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2024-01-22 09:30:43,713 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,716 Corpus: 11355 train + 1262 dev + 1402 test sentences\n",
            "2024-01-22 09:30:43,717 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,718 Train:  12617 sentences\n",
            "2024-01-22 09:30:43,720         (train_with_dev=True, train_with_test=False)\n",
            "2024-01-22 09:30:43,721 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,722 Training Params:\n",
            "2024-01-22 09:30:43,723  - learning_rate: \"0.1\" \n",
            "2024-01-22 09:30:43,725  - mini_batch_size: \"32\"\n",
            "2024-01-22 09:30:43,726  - max_epochs: \"250\"\n",
            "2024-01-22 09:30:43,727  - shuffle: \"True\"\n",
            "2024-01-22 09:30:43,729 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,730 Plugins:\n",
            "2024-01-22 09:30:43,731  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2024-01-22 09:30:43,733 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,734 Final evaluation on model from best epoch (best-model.pt)\n",
            "2024-01-22 09:30:43,735  - metric: \"('micro avg', 'f1-score')\"\n",
            "2024-01-22 09:30:43,737 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,738 Computation:\n",
            "2024-01-22 09:30:43,739  - compute on device: cuda:0\n",
            "2024-01-22 09:30:43,740  - embedding storage: cpu\n",
            "2024-01-22 09:30:43,742 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,743 Model training base path: \"resources/taggers/example-ner\"\n",
            "2024-01-22 09:30:43,744 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,745 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:30:43,747 train mode resetting embeddings\n",
            "2024-01-22 09:30:43,747 train mode resetting embeddings\n",
            "2024-01-22 09:31:16,365 epoch 1 - iter 39/395 - loss 0.98743686 - time (sec): 32.62 - samples/sec: 2263.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:32:05,597 epoch 1 - iter 78/395 - loss 0.76935557 - time (sec): 81.85 - samples/sec: 1792.62 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:32:40,323 epoch 1 - iter 117/395 - loss 0.63651479 - time (sec): 116.57 - samples/sec: 1923.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:33:11,561 epoch 1 - iter 156/395 - loss 0.56063740 - time (sec): 147.81 - samples/sec: 2027.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:33:43,125 epoch 1 - iter 195/395 - loss 0.50786828 - time (sec): 179.38 - samples/sec: 2083.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:34:16,370 epoch 1 - iter 234/395 - loss 0.46570436 - time (sec): 212.62 - samples/sec: 2113.87 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:34:47,365 epoch 1 - iter 273/395 - loss 0.43635707 - time (sec): 243.62 - samples/sec: 2143.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:35:18,881 epoch 1 - iter 312/395 - loss 0.41121451 - time (sec): 275.13 - samples/sec: 2169.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:35:52,625 epoch 1 - iter 351/395 - loss 0.39194954 - time (sec): 308.88 - samples/sec: 2176.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:36:25,899 epoch 1 - iter 390/395 - loss 0.37488287 - time (sec): 342.15 - samples/sec: 2187.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:36:29,075 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:36:29,077 EPOCH 1 done: loss 0.3732 - lr: 0.100000\n",
            "2024-01-22 09:36:29,078  - 0 epochs without improvement\n",
            "2024-01-22 09:36:29,080 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:36:29,081 train mode resetting embeddings\n",
            "2024-01-22 09:36:29,088 train mode resetting embeddings\n",
            "2024-01-22 09:36:48,228 epoch 2 - iter 39/395 - loss 0.22425595 - time (sec): 19.14 - samples/sec: 3941.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:37:09,525 epoch 2 - iter 78/395 - loss 0.22385280 - time (sec): 40.43 - samples/sec: 3723.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:37:28,452 epoch 2 - iter 117/395 - loss 0.21856633 - time (sec): 59.36 - samples/sec: 3794.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:37:50,288 epoch 2 - iter 156/395 - loss 0.21637744 - time (sec): 81.20 - samples/sec: 3691.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:38:09,610 epoch 2 - iter 195/395 - loss 0.21299309 - time (sec): 100.52 - samples/sec: 3728.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:38:29,914 epoch 2 - iter 234/395 - loss 0.21164122 - time (sec): 120.82 - samples/sec: 3719.39 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:38:49,504 epoch 2 - iter 273/395 - loss 0.20906741 - time (sec): 140.41 - samples/sec: 3727.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:39:09,002 epoch 2 - iter 312/395 - loss 0.20766497 - time (sec): 159.91 - samples/sec: 3741.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:39:27,981 epoch 2 - iter 351/395 - loss 0.20649485 - time (sec): 178.89 - samples/sec: 3758.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:39:47,547 epoch 2 - iter 390/395 - loss 0.20529449 - time (sec): 198.45 - samples/sec: 3769.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:39:49,636 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:39:49,637 EPOCH 2 done: loss 0.2051 - lr: 0.100000\n",
            "2024-01-22 09:39:49,639  - 0 epochs without improvement\n",
            "2024-01-22 09:39:49,641 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:39:49,642 train mode resetting embeddings\n",
            "2024-01-22 09:39:49,643 train mode resetting embeddings\n",
            "2024-01-22 09:40:08,299 epoch 3 - iter 39/395 - loss 0.19428995 - time (sec): 18.65 - samples/sec: 3955.84 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:40:31,879 epoch 3 - iter 78/395 - loss 0.19098117 - time (sec): 42.23 - samples/sec: 3550.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:40:52,229 epoch 3 - iter 117/395 - loss 0.18913079 - time (sec): 62.58 - samples/sec: 3597.62 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:41:11,033 epoch 3 - iter 156/395 - loss 0.18889061 - time (sec): 81.39 - samples/sec: 3655.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:41:30,263 epoch 3 - iter 195/395 - loss 0.18868962 - time (sec): 100.62 - samples/sec: 3695.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:41:51,925 epoch 3 - iter 234/395 - loss 0.18775231 - time (sec): 122.28 - samples/sec: 3667.40 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:42:12,770 epoch 3 - iter 273/395 - loss 0.18719862 - time (sec): 143.12 - samples/sec: 3664.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:42:32,006 epoch 3 - iter 312/395 - loss 0.18715542 - time (sec): 162.36 - samples/sec: 3691.23 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:42:50,002 epoch 3 - iter 351/395 - loss 0.18650833 - time (sec): 180.36 - samples/sec: 3729.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:43:13,052 epoch 3 - iter 390/395 - loss 0.18564041 - time (sec): 203.41 - samples/sec: 3679.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:43:15,025 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:43:15,026 EPOCH 3 done: loss 0.1856 - lr: 0.100000\n",
            "2024-01-22 09:43:15,028  - 0 epochs without improvement\n",
            "2024-01-22 09:43:15,030 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:43:15,031 train mode resetting embeddings\n",
            "2024-01-22 09:43:15,032 train mode resetting embeddings\n",
            "2024-01-22 09:43:34,031 epoch 4 - iter 39/395 - loss 0.17858589 - time (sec): 19.00 - samples/sec: 3864.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:43:53,647 epoch 4 - iter 78/395 - loss 0.17712440 - time (sec): 38.61 - samples/sec: 3826.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:44:12,364 epoch 4 - iter 117/395 - loss 0.17698948 - time (sec): 57.33 - samples/sec: 3859.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:44:32,329 epoch 4 - iter 156/395 - loss 0.17725784 - time (sec): 77.30 - samples/sec: 3852.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:44:52,791 epoch 4 - iter 195/395 - loss 0.17775594 - time (sec): 97.76 - samples/sec: 3811.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:45:12,315 epoch 4 - iter 234/395 - loss 0.17777215 - time (sec): 117.28 - samples/sec: 3818.78 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:45:34,702 epoch 4 - iter 273/395 - loss 0.17714988 - time (sec): 139.67 - samples/sec: 3760.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:45:55,942 epoch 4 - iter 312/395 - loss 0.17678863 - time (sec): 160.91 - samples/sec: 3723.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:46:14,650 epoch 4 - iter 351/395 - loss 0.17667015 - time (sec): 179.62 - samples/sec: 3748.82 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:46:34,588 epoch 4 - iter 390/395 - loss 0.17553648 - time (sec): 199.56 - samples/sec: 3750.58 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:46:36,659 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:46:36,660 EPOCH 4 done: loss 0.1755 - lr: 0.100000\n",
            "2024-01-22 09:46:36,662  - 0 epochs without improvement\n",
            "2024-01-22 09:46:36,664 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:46:36,665 train mode resetting embeddings\n",
            "2024-01-22 09:46:36,666 train mode resetting embeddings\n",
            "2024-01-22 09:46:55,895 epoch 5 - iter 39/395 - loss 0.17171923 - time (sec): 19.23 - samples/sec: 3857.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:47:19,351 epoch 5 - iter 78/395 - loss 0.17204124 - time (sec): 42.68 - samples/sec: 3560.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:47:38,759 epoch 5 - iter 117/395 - loss 0.17122362 - time (sec): 62.09 - samples/sec: 3661.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:47:57,560 epoch 5 - iter 156/395 - loss 0.17122891 - time (sec): 80.89 - samples/sec: 3727.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:48:17,694 epoch 5 - iter 195/395 - loss 0.17098180 - time (sec): 101.03 - samples/sec: 3728.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:48:39,590 epoch 5 - iter 234/395 - loss 0.17173473 - time (sec): 122.92 - samples/sec: 3668.01 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:48:58,358 epoch 5 - iter 273/395 - loss 0.17174384 - time (sec): 141.69 - samples/sec: 3697.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:49:16,808 epoch 5 - iter 312/395 - loss 0.17108410 - time (sec): 160.14 - samples/sec: 3729.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:49:36,391 epoch 5 - iter 351/395 - loss 0.17032814 - time (sec): 179.72 - samples/sec: 3740.51 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:49:57,204 epoch 5 - iter 390/395 - loss 0.17023430 - time (sec): 200.54 - samples/sec: 3732.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:49:59,063 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:49:59,065 EPOCH 5 done: loss 0.1701 - lr: 0.100000\n",
            "2024-01-22 09:49:59,066  - 0 epochs without improvement\n",
            "2024-01-22 09:49:59,068 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:49:59,069 train mode resetting embeddings\n",
            "2024-01-22 09:49:59,070 train mode resetting embeddings\n",
            "2024-01-22 09:50:17,950 epoch 6 - iter 39/395 - loss 0.17302459 - time (sec): 18.88 - samples/sec: 3909.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:50:36,203 epoch 6 - iter 78/395 - loss 0.16964382 - time (sec): 37.13 - samples/sec: 3975.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:50:54,374 epoch 6 - iter 117/395 - loss 0.16830284 - time (sec): 55.30 - samples/sec: 3991.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:51:18,254 epoch 6 - iter 156/395 - loss 0.16724829 - time (sec): 79.18 - samples/sec: 3767.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:51:39,561 epoch 6 - iter 195/395 - loss 0.16658620 - time (sec): 100.49 - samples/sec: 3732.84 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:51:58,612 epoch 6 - iter 234/395 - loss 0.16578152 - time (sec): 119.54 - samples/sec: 3759.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:52:18,103 epoch 6 - iter 273/395 - loss 0.16584257 - time (sec): 139.03 - samples/sec: 3763.54 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:52:37,082 epoch 6 - iter 312/395 - loss 0.16617592 - time (sec): 158.01 - samples/sec: 3782.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:52:58,846 epoch 6 - iter 351/395 - loss 0.16581197 - time (sec): 179.78 - samples/sec: 3746.48 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:53:17,332 epoch 6 - iter 390/395 - loss 0.16542563 - time (sec): 198.26 - samples/sec: 3767.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:53:21,050 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:53:21,052 EPOCH 6 done: loss 0.1654 - lr: 0.100000\n",
            "2024-01-22 09:53:21,054  - 0 epochs without improvement\n",
            "2024-01-22 09:53:21,055 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:53:21,057 train mode resetting embeddings\n",
            "2024-01-22 09:53:21,058 train mode resetting embeddings\n",
            "2024-01-22 09:53:40,827 epoch 7 - iter 39/395 - loss 0.16674949 - time (sec): 19.77 - samples/sec: 3825.96 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:54:01,603 epoch 7 - iter 78/395 - loss 0.16504344 - time (sec): 40.54 - samples/sec: 3709.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:54:20,190 epoch 7 - iter 117/395 - loss 0.16465458 - time (sec): 59.13 - samples/sec: 3779.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:54:40,812 epoch 7 - iter 156/395 - loss 0.16399149 - time (sec): 79.75 - samples/sec: 3736.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:55:00,193 epoch 7 - iter 195/395 - loss 0.16380260 - time (sec): 99.13 - samples/sec: 3756.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:55:19,218 epoch 7 - iter 234/395 - loss 0.16447343 - time (sec): 118.16 - samples/sec: 3775.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:55:37,797 epoch 7 - iter 273/395 - loss 0.16365118 - time (sec): 136.74 - samples/sec: 3808.58 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:55:57,730 epoch 7 - iter 312/395 - loss 0.16410213 - time (sec): 156.67 - samples/sec: 3797.99 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:56:17,478 epoch 7 - iter 351/395 - loss 0.16343512 - time (sec): 176.42 - samples/sec: 3806.77 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:56:42,813 epoch 7 - iter 390/395 - loss 0.16264982 - time (sec): 201.75 - samples/sec: 3705.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:56:45,604 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:56:45,606 EPOCH 7 done: loss 0.1626 - lr: 0.100000\n",
            "2024-01-22 09:56:45,607  - 0 epochs without improvement\n",
            "2024-01-22 09:56:45,609 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 09:56:45,610 train mode resetting embeddings\n",
            "2024-01-22 09:56:45,612 train mode resetting embeddings\n",
            "2024-01-22 09:57:03,921 epoch 8 - iter 39/395 - loss 0.15510656 - time (sec): 18.31 - samples/sec: 4019.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:57:27,632 epoch 8 - iter 78/395 - loss 0.15700000 - time (sec): 42.02 - samples/sec: 3591.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:57:46,982 epoch 8 - iter 117/395 - loss 0.15843796 - time (sec): 61.37 - samples/sec: 3671.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:58:04,889 epoch 8 - iter 156/395 - loss 0.15859570 - time (sec): 79.28 - samples/sec: 3779.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:58:25,081 epoch 8 - iter 195/395 - loss 0.15802813 - time (sec): 99.47 - samples/sec: 3751.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:58:44,551 epoch 8 - iter 234/395 - loss 0.15818500 - time (sec): 118.94 - samples/sec: 3769.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:59:06,156 epoch 8 - iter 273/395 - loss 0.15755486 - time (sec): 140.54 - samples/sec: 3714.48 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:59:26,107 epoch 8 - iter 312/395 - loss 0.15781597 - time (sec): 160.49 - samples/sec: 3719.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 09:59:45,353 epoch 8 - iter 351/395 - loss 0.15795536 - time (sec): 179.74 - samples/sec: 3742.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:00:04,997 epoch 8 - iter 390/395 - loss 0.15751373 - time (sec): 199.38 - samples/sec: 3750.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:00:07,087 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:00:07,089 EPOCH 8 done: loss 0.1576 - lr: 0.100000\n",
            "2024-01-22 10:00:07,090  - 0 epochs without improvement\n",
            "2024-01-22 10:00:07,092 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:00:07,094 train mode resetting embeddings\n",
            "2024-01-22 10:00:07,095 train mode resetting embeddings\n",
            "2024-01-22 10:00:26,740 epoch 9 - iter 39/395 - loss 0.15348659 - time (sec): 19.64 - samples/sec: 3819.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:00:44,842 epoch 9 - iter 78/395 - loss 0.15366481 - time (sec): 37.75 - samples/sec: 3923.21 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:01:04,760 epoch 9 - iter 117/395 - loss 0.15362971 - time (sec): 57.66 - samples/sec: 3888.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:01:23,731 epoch 9 - iter 156/395 - loss 0.15388982 - time (sec): 76.64 - samples/sec: 3897.62 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:01:46,569 epoch 9 - iter 195/395 - loss 0.15440350 - time (sec): 99.47 - samples/sec: 3764.83 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:02:04,961 epoch 9 - iter 234/395 - loss 0.15489475 - time (sec): 117.86 - samples/sec: 3806.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:02:25,272 epoch 9 - iter 273/395 - loss 0.15484273 - time (sec): 138.18 - samples/sec: 3785.92 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:02:44,516 epoch 9 - iter 312/395 - loss 0.15559010 - time (sec): 157.42 - samples/sec: 3801.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:03:03,693 epoch 9 - iter 351/395 - loss 0.15522835 - time (sec): 176.60 - samples/sec: 3808.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:03:24,794 epoch 9 - iter 390/395 - loss 0.15553044 - time (sec): 197.70 - samples/sec: 3785.72 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:03:26,765 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:03:26,766 EPOCH 9 done: loss 0.1555 - lr: 0.100000\n",
            "2024-01-22 10:03:26,767  - 0 epochs without improvement\n",
            "2024-01-22 10:03:26,770 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:03:26,772 train mode resetting embeddings\n",
            "2024-01-22 10:03:26,773 train mode resetting embeddings\n",
            "2024-01-22 10:03:46,157 epoch 10 - iter 39/395 - loss 0.15505915 - time (sec): 19.38 - samples/sec: 3839.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:04:05,557 epoch 10 - iter 78/395 - loss 0.15562767 - time (sec): 38.78 - samples/sec: 3842.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:04:26,060 epoch 10 - iter 117/395 - loss 0.15579364 - time (sec): 59.28 - samples/sec: 3754.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:04:44,952 epoch 10 - iter 156/395 - loss 0.15484047 - time (sec): 78.18 - samples/sec: 3806.72 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:05:05,541 epoch 10 - iter 195/395 - loss 0.15325230 - time (sec): 98.77 - samples/sec: 3779.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:05:25,929 epoch 10 - iter 234/395 - loss 0.15346523 - time (sec): 119.15 - samples/sec: 3763.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:05:45,624 epoch 10 - iter 273/395 - loss 0.15345024 - time (sec): 138.85 - samples/sec: 3771.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:06:06,737 epoch 10 - iter 312/395 - loss 0.15331513 - time (sec): 159.96 - samples/sec: 3744.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:06:25,771 epoch 10 - iter 351/395 - loss 0.15374590 - time (sec): 179.00 - samples/sec: 3763.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:06:43,803 epoch 10 - iter 390/395 - loss 0.15395443 - time (sec): 197.03 - samples/sec: 3797.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:06:45,967 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:06:45,969 EPOCH 10 done: loss 0.1538 - lr: 0.100000\n",
            "2024-01-22 10:06:45,970  - 0 epochs without improvement\n",
            "2024-01-22 10:06:45,972 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:06:45,973 train mode resetting embeddings\n",
            "2024-01-22 10:06:45,974 train mode resetting embeddings\n",
            "2024-01-22 10:07:07,219 epoch 11 - iter 39/395 - loss 0.15714967 - time (sec): 21.24 - samples/sec: 3498.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:07:26,771 epoch 11 - iter 78/395 - loss 0.15241690 - time (sec): 40.80 - samples/sec: 3653.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:07:45,896 epoch 11 - iter 117/395 - loss 0.15096232 - time (sec): 59.92 - samples/sec: 3739.90 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:08:04,147 epoch 11 - iter 156/395 - loss 0.15079036 - time (sec): 78.17 - samples/sec: 3807.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:08:22,653 epoch 11 - iter 195/395 - loss 0.15204714 - time (sec): 96.68 - samples/sec: 3844.78 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:08:41,654 epoch 11 - iter 234/395 - loss 0.15220429 - time (sec): 115.68 - samples/sec: 3856.84 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:09:02,528 epoch 11 - iter 273/395 - loss 0.15331521 - time (sec): 136.55 - samples/sec: 3824.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:09:20,928 epoch 11 - iter 312/395 - loss 0.15265881 - time (sec): 154.95 - samples/sec: 3845.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:09:45,532 epoch 11 - iter 351/395 - loss 0.15360015 - time (sec): 179.56 - samples/sec: 3750.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:10:04,817 epoch 11 - iter 390/395 - loss 0.15284991 - time (sec): 198.84 - samples/sec: 3764.96 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:10:06,835 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:10:06,836 EPOCH 11 done: loss 0.1528 - lr: 0.100000\n",
            "2024-01-22 10:10:06,837  - 0 epochs without improvement\n",
            "2024-01-22 10:10:06,840 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:10:06,842 train mode resetting embeddings\n",
            "2024-01-22 10:10:06,843 train mode resetting embeddings\n",
            "2024-01-22 10:10:24,803 epoch 12 - iter 39/395 - loss 0.15122050 - time (sec): 17.96 - samples/sec: 4066.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:10:44,072 epoch 12 - iter 78/395 - loss 0.15143011 - time (sec): 37.23 - samples/sec: 3942.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:11:02,517 epoch 12 - iter 117/395 - loss 0.15183333 - time (sec): 55.67 - samples/sec: 3976.66 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:11:21,472 epoch 12 - iter 156/395 - loss 0.15065002 - time (sec): 74.63 - samples/sec: 3963.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:11:43,081 epoch 12 - iter 195/395 - loss 0.15113989 - time (sec): 96.24 - samples/sec: 3861.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:12:02,173 epoch 12 - iter 234/395 - loss 0.15017420 - time (sec): 115.33 - samples/sec: 3868.37 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:12:23,306 epoch 12 - iter 273/395 - loss 0.15007336 - time (sec): 136.46 - samples/sec: 3815.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:12:41,620 epoch 12 - iter 312/395 - loss 0.15025409 - time (sec): 154.78 - samples/sec: 3843.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:13:01,513 epoch 12 - iter 351/395 - loss 0.15038470 - time (sec): 174.67 - samples/sec: 3843.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:13:22,404 epoch 12 - iter 390/395 - loss 0.15032889 - time (sec): 195.56 - samples/sec: 3824.61 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:13:24,422 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:13:24,423 EPOCH 12 done: loss 0.1503 - lr: 0.100000\n",
            "2024-01-22 10:13:24,425  - 0 epochs without improvement\n",
            "2024-01-22 10:13:24,427 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:13:24,428 train mode resetting embeddings\n",
            "2024-01-22 10:13:24,430 train mode resetting embeddings\n",
            "2024-01-22 10:13:43,159 epoch 13 - iter 39/395 - loss 0.15085440 - time (sec): 18.73 - samples/sec: 3958.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:14:02,371 epoch 13 - iter 78/395 - loss 0.14910035 - time (sec): 37.94 - samples/sec: 3898.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:14:21,554 epoch 13 - iter 117/395 - loss 0.14898465 - time (sec): 57.12 - samples/sec: 3916.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:14:41,529 epoch 13 - iter 156/395 - loss 0.14943309 - time (sec): 77.10 - samples/sec: 3878.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:15:02,134 epoch 13 - iter 195/395 - loss 0.14991770 - time (sec): 97.70 - samples/sec: 3814.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:15:20,952 epoch 13 - iter 234/395 - loss 0.14905001 - time (sec): 116.52 - samples/sec: 3832.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:15:40,846 epoch 13 - iter 273/395 - loss 0.14935255 - time (sec): 136.41 - samples/sec: 3826.77 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:16:00,389 epoch 13 - iter 312/395 - loss 0.14927862 - time (sec): 155.96 - samples/sec: 3831.01 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:16:18,869 epoch 13 - iter 351/395 - loss 0.14957350 - time (sec): 174.44 - samples/sec: 3849.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:16:41,184 epoch 13 - iter 390/395 - loss 0.14902026 - time (sec): 196.75 - samples/sec: 3801.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:16:43,218 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:16:43,220 EPOCH 13 done: loss 0.1489 - lr: 0.100000\n",
            "2024-01-22 10:16:43,221  - 0 epochs without improvement\n",
            "2024-01-22 10:16:43,223 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:16:43,224 train mode resetting embeddings\n",
            "2024-01-22 10:16:43,224 train mode resetting embeddings\n",
            "2024-01-22 10:17:02,319 epoch 14 - iter 39/395 - loss 0.15040525 - time (sec): 19.09 - samples/sec: 3955.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:17:20,096 epoch 14 - iter 78/395 - loss 0.15001986 - time (sec): 36.87 - samples/sec: 4012.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:17:43,882 epoch 14 - iter 117/395 - loss 0.14946780 - time (sec): 60.66 - samples/sec: 3708.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:18:03,468 epoch 14 - iter 156/395 - loss 0.14885123 - time (sec): 80.24 - samples/sec: 3743.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:18:22,939 epoch 14 - iter 195/395 - loss 0.14832348 - time (sec): 99.71 - samples/sec: 3761.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:18:43,270 epoch 14 - iter 234/395 - loss 0.14916082 - time (sec): 120.04 - samples/sec: 3760.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:19:01,609 epoch 14 - iter 273/395 - loss 0.14898480 - time (sec): 138.38 - samples/sec: 3792.92 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:19:22,793 epoch 14 - iter 312/395 - loss 0.14883919 - time (sec): 159.57 - samples/sec: 3770.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:19:40,955 epoch 14 - iter 351/395 - loss 0.14897960 - time (sec): 177.73 - samples/sec: 3790.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:19:59,788 epoch 14 - iter 390/395 - loss 0.14849156 - time (sec): 196.56 - samples/sec: 3802.93 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:20:02,285 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:20:02,287 EPOCH 14 done: loss 0.1483 - lr: 0.100000\n",
            "2024-01-22 10:20:02,289  - 0 epochs without improvement\n",
            "2024-01-22 10:20:02,291 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:20:02,292 train mode resetting embeddings\n",
            "2024-01-22 10:20:02,293 train mode resetting embeddings\n",
            "2024-01-22 10:20:26,203 epoch 15 - iter 39/395 - loss 0.14984226 - time (sec): 23.91 - samples/sec: 3144.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:20:46,308 epoch 15 - iter 78/395 - loss 0.14910008 - time (sec): 44.01 - samples/sec: 3417.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:21:05,541 epoch 15 - iter 117/395 - loss 0.14715742 - time (sec): 63.25 - samples/sec: 3552.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:21:24,029 epoch 15 - iter 156/395 - loss 0.14726866 - time (sec): 81.73 - samples/sec: 3648.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:21:43,423 epoch 15 - iter 195/395 - loss 0.14701818 - time (sec): 101.13 - samples/sec: 3686.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:22:04,361 epoch 15 - iter 234/395 - loss 0.14677773 - time (sec): 122.07 - samples/sec: 3671.65 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:22:23,748 epoch 15 - iter 273/395 - loss 0.14642587 - time (sec): 141.45 - samples/sec: 3697.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:22:45,727 epoch 15 - iter 312/395 - loss 0.14625039 - time (sec): 163.43 - samples/sec: 3656.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:23:04,431 epoch 15 - iter 351/395 - loss 0.14632845 - time (sec): 182.14 - samples/sec: 3682.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:23:23,608 epoch 15 - iter 390/395 - loss 0.14675667 - time (sec): 201.31 - samples/sec: 3713.99 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:23:25,840 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:23:25,842 EPOCH 15 done: loss 0.1468 - lr: 0.100000\n",
            "2024-01-22 10:23:25,844  - 0 epochs without improvement\n",
            "2024-01-22 10:23:25,845 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:23:25,847 train mode resetting embeddings\n",
            "2024-01-22 10:23:25,848 train mode resetting embeddings\n",
            "2024-01-22 10:23:43,986 epoch 16 - iter 39/395 - loss 0.14165745 - time (sec): 18.14 - samples/sec: 4027.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:24:03,248 epoch 16 - iter 78/395 - loss 0.14187566 - time (sec): 37.40 - samples/sec: 3949.39 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:24:25,312 epoch 16 - iter 117/395 - loss 0.14331170 - time (sec): 59.46 - samples/sec: 3784.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:24:44,642 epoch 16 - iter 156/395 - loss 0.14396553 - time (sec): 78.79 - samples/sec: 3809.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:25:05,841 epoch 16 - iter 195/395 - loss 0.14381335 - time (sec): 99.99 - samples/sec: 3771.46 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:25:27,801 epoch 16 - iter 234/395 - loss 0.14456845 - time (sec): 121.95 - samples/sec: 3709.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:25:46,014 epoch 16 - iter 273/395 - loss 0.14464345 - time (sec): 140.16 - samples/sec: 3752.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:26:04,621 epoch 16 - iter 312/395 - loss 0.14517421 - time (sec): 158.77 - samples/sec: 3776.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:26:23,883 epoch 16 - iter 351/395 - loss 0.14488585 - time (sec): 178.03 - samples/sec: 3791.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:26:42,655 epoch 16 - iter 390/395 - loss 0.14466626 - time (sec): 196.80 - samples/sec: 3802.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:26:44,607 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:26:44,608 EPOCH 16 done: loss 0.1447 - lr: 0.100000\n",
            "2024-01-22 10:26:44,610  - 0 epochs without improvement\n",
            "2024-01-22 10:26:44,612 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:26:44,614 train mode resetting embeddings\n",
            "2024-01-22 10:26:44,615 train mode resetting embeddings\n",
            "2024-01-22 10:27:04,305 epoch 17 - iter 39/395 - loss 0.14243618 - time (sec): 19.69 - samples/sec: 3810.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:27:23,000 epoch 17 - iter 78/395 - loss 0.14244530 - time (sec): 38.38 - samples/sec: 3851.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:27:43,432 epoch 17 - iter 117/395 - loss 0.14387471 - time (sec): 58.82 - samples/sec: 3796.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:28:05,965 epoch 17 - iter 156/395 - loss 0.14304279 - time (sec): 81.35 - samples/sec: 3672.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:28:24,761 epoch 17 - iter 195/395 - loss 0.14418100 - time (sec): 100.14 - samples/sec: 3722.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:28:46,589 epoch 17 - iter 234/395 - loss 0.14379952 - time (sec): 121.97 - samples/sec: 3680.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:29:05,231 epoch 17 - iter 273/395 - loss 0.14329045 - time (sec): 140.61 - samples/sec: 3725.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:29:24,407 epoch 17 - iter 312/395 - loss 0.14396951 - time (sec): 159.79 - samples/sec: 3745.40 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:29:42,523 epoch 17 - iter 351/395 - loss 0.14388344 - time (sec): 177.91 - samples/sec: 3778.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:30:02,435 epoch 17 - iter 390/395 - loss 0.14389296 - time (sec): 197.82 - samples/sec: 3783.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:30:04,341 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:30:04,343 EPOCH 17 done: loss 0.1440 - lr: 0.100000\n",
            "2024-01-22 10:30:04,345  - 0 epochs without improvement\n",
            "2024-01-22 10:30:04,347 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:30:04,349 train mode resetting embeddings\n",
            "2024-01-22 10:30:04,349 train mode resetting embeddings\n",
            "2024-01-22 10:30:26,444 epoch 18 - iter 39/395 - loss 0.14442352 - time (sec): 22.09 - samples/sec: 3492.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:30:47,873 epoch 18 - iter 78/395 - loss 0.14337407 - time (sec): 43.52 - samples/sec: 3493.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:31:07,470 epoch 18 - iter 117/395 - loss 0.14218987 - time (sec): 63.12 - samples/sec: 3592.04 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:31:26,575 epoch 18 - iter 156/395 - loss 0.14350088 - time (sec): 82.22 - samples/sec: 3653.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:31:45,500 epoch 18 - iter 195/395 - loss 0.14322698 - time (sec): 101.15 - samples/sec: 3705.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:32:04,582 epoch 18 - iter 234/395 - loss 0.14317856 - time (sec): 120.23 - samples/sec: 3734.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:32:23,117 epoch 18 - iter 273/395 - loss 0.14305761 - time (sec): 138.77 - samples/sec: 3774.87 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:32:41,991 epoch 18 - iter 312/395 - loss 0.14334986 - time (sec): 157.64 - samples/sec: 3790.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:33:04,506 epoch 18 - iter 351/395 - loss 0.14320750 - time (sec): 180.16 - samples/sec: 3739.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:33:25,837 epoch 18 - iter 390/395 - loss 0.14336166 - time (sec): 201.49 - samples/sec: 3713.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:33:28,040 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:33:28,041 EPOCH 18 done: loss 0.1433 - lr: 0.100000\n",
            "2024-01-22 10:33:28,043  - 0 epochs without improvement\n",
            "2024-01-22 10:33:28,045 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:33:28,046 train mode resetting embeddings\n",
            "2024-01-22 10:33:28,048 train mode resetting embeddings\n",
            "2024-01-22 10:33:46,944 epoch 19 - iter 39/395 - loss 0.14170146 - time (sec): 18.89 - samples/sec: 3956.56 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:34:05,317 epoch 19 - iter 78/395 - loss 0.14283881 - time (sec): 37.27 - samples/sec: 3946.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:34:24,140 epoch 19 - iter 117/395 - loss 0.14388025 - time (sec): 56.09 - samples/sec: 3937.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:34:42,549 epoch 19 - iter 156/395 - loss 0.14262750 - time (sec): 74.50 - samples/sec: 3953.46 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:35:01,894 epoch 19 - iter 195/395 - loss 0.14328111 - time (sec): 93.84 - samples/sec: 3938.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:35:21,347 epoch 19 - iter 234/395 - loss 0.14373364 - time (sec): 113.30 - samples/sec: 3929.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:35:40,428 epoch 19 - iter 273/395 - loss 0.14362419 - time (sec): 132.38 - samples/sec: 3921.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:36:05,162 epoch 19 - iter 312/395 - loss 0.14295587 - time (sec): 157.11 - samples/sec: 3788.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:36:26,616 epoch 19 - iter 351/395 - loss 0.14299362 - time (sec): 178.57 - samples/sec: 3764.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:36:46,067 epoch 19 - iter 390/395 - loss 0.14287156 - time (sec): 198.02 - samples/sec: 3777.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:36:48,163 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:36:48,164 EPOCH 19 done: loss 0.1430 - lr: 0.100000\n",
            "2024-01-22 10:36:48,166  - 0 epochs without improvement\n",
            "2024-01-22 10:36:48,168 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:36:48,170 train mode resetting embeddings\n",
            "2024-01-22 10:36:48,171 train mode resetting embeddings\n",
            "2024-01-22 10:37:07,187 epoch 20 - iter 39/395 - loss 0.13502872 - time (sec): 19.02 - samples/sec: 3963.96 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:37:25,793 epoch 20 - iter 78/395 - loss 0.13694926 - time (sec): 37.62 - samples/sec: 3951.04 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:37:46,258 epoch 20 - iter 117/395 - loss 0.13779213 - time (sec): 58.09 - samples/sec: 3882.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:38:04,853 epoch 20 - iter 156/395 - loss 0.13843301 - time (sec): 76.68 - samples/sec: 3914.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:38:23,265 epoch 20 - iter 195/395 - loss 0.13851415 - time (sec): 95.09 - samples/sec: 3922.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:38:44,691 epoch 20 - iter 234/395 - loss 0.13974922 - time (sec): 116.52 - samples/sec: 3839.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:39:02,895 epoch 20 - iter 273/395 - loss 0.13979748 - time (sec): 134.72 - samples/sec: 3860.72 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:39:24,812 epoch 20 - iter 312/395 - loss 0.13939941 - time (sec): 156.64 - samples/sec: 3811.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:39:44,215 epoch 20 - iter 351/395 - loss 0.13934644 - time (sec): 176.04 - samples/sec: 3816.87 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:40:04,624 epoch 20 - iter 390/395 - loss 0.13999401 - time (sec): 196.45 - samples/sec: 3808.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:40:06,753 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:40:06,754 EPOCH 20 done: loss 0.1401 - lr: 0.100000\n",
            "2024-01-22 10:40:06,756  - 0 epochs without improvement\n",
            "2024-01-22 10:40:06,758 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:40:06,760 train mode resetting embeddings\n",
            "2024-01-22 10:40:06,761 train mode resetting embeddings\n",
            "2024-01-22 10:40:25,473 epoch 21 - iter 39/395 - loss 0.13776407 - time (sec): 18.71 - samples/sec: 3906.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:40:44,097 epoch 21 - iter 78/395 - loss 0.13846444 - time (sec): 37.34 - samples/sec: 3922.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:41:06,924 epoch 21 - iter 117/395 - loss 0.14151397 - time (sec): 60.16 - samples/sec: 3692.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:41:29,639 epoch 21 - iter 156/395 - loss 0.14036331 - time (sec): 82.88 - samples/sec: 3582.37 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:41:48,266 epoch 21 - iter 195/395 - loss 0.14007420 - time (sec): 101.50 - samples/sec: 3660.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:42:07,085 epoch 21 - iter 234/395 - loss 0.14063025 - time (sec): 120.32 - samples/sec: 3708.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:42:25,375 epoch 21 - iter 273/395 - loss 0.14034679 - time (sec): 138.61 - samples/sec: 3750.83 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:42:43,724 epoch 21 - iter 312/395 - loss 0.14058490 - time (sec): 156.96 - samples/sec: 3791.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:43:04,052 epoch 21 - iter 351/395 - loss 0.14069307 - time (sec): 177.29 - samples/sec: 3783.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:43:24,073 epoch 21 - iter 390/395 - loss 0.14067993 - time (sec): 197.31 - samples/sec: 3787.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:43:26,760 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:43:26,761 EPOCH 21 done: loss 0.1406 - lr: 0.100000\n",
            "2024-01-22 10:43:26,763  - 1 epochs without improvement\n",
            "2024-01-22 10:43:26,764 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:43:26,766 train mode resetting embeddings\n",
            "2024-01-22 10:43:26,768 train mode resetting embeddings\n",
            "2024-01-22 10:43:46,029 epoch 22 - iter 39/395 - loss 0.13256492 - time (sec): 19.26 - samples/sec: 3820.39 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:44:07,464 epoch 22 - iter 78/395 - loss 0.13585898 - time (sec): 40.69 - samples/sec: 3637.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:44:26,006 epoch 22 - iter 117/395 - loss 0.13740016 - time (sec): 59.24 - samples/sec: 3748.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:44:46,312 epoch 22 - iter 156/395 - loss 0.13797821 - time (sec): 79.54 - samples/sec: 3756.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:45:05,398 epoch 22 - iter 195/395 - loss 0.13812889 - time (sec): 98.63 - samples/sec: 3790.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:45:25,490 epoch 22 - iter 234/395 - loss 0.13888594 - time (sec): 118.72 - samples/sec: 3778.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:45:44,197 epoch 22 - iter 273/395 - loss 0.13876856 - time (sec): 137.43 - samples/sec: 3804.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:46:03,065 epoch 22 - iter 312/395 - loss 0.13898661 - time (sec): 156.30 - samples/sec: 3819.38 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:46:26,876 epoch 22 - iter 351/395 - loss 0.13832754 - time (sec): 180.11 - samples/sec: 3747.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:46:47,499 epoch 22 - iter 390/395 - loss 0.13862316 - time (sec): 200.73 - samples/sec: 3726.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:46:49,953 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:46:49,955 EPOCH 22 done: loss 0.1388 - lr: 0.100000\n",
            "2024-01-22 10:46:49,956  - 0 epochs without improvement\n",
            "2024-01-22 10:46:49,958 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:46:49,959 train mode resetting embeddings\n",
            "2024-01-22 10:46:49,960 train mode resetting embeddings\n",
            "2024-01-22 10:47:11,465 epoch 23 - iter 39/395 - loss 0.14233468 - time (sec): 21.50 - samples/sec: 3539.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:47:33,800 epoch 23 - iter 78/395 - loss 0.13926806 - time (sec): 43.84 - samples/sec: 3504.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:47:52,759 epoch 23 - iter 117/395 - loss 0.14060735 - time (sec): 62.80 - samples/sec: 3628.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:48:11,623 epoch 23 - iter 156/395 - loss 0.13901122 - time (sec): 81.66 - samples/sec: 3696.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:48:30,394 epoch 23 - iter 195/395 - loss 0.14064172 - time (sec): 100.43 - samples/sec: 3742.65 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:48:48,945 epoch 23 - iter 234/395 - loss 0.13952772 - time (sec): 118.98 - samples/sec: 3790.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:49:09,981 epoch 23 - iter 273/395 - loss 0.13859807 - time (sec): 140.02 - samples/sec: 3739.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:49:28,987 epoch 23 - iter 312/395 - loss 0.13774246 - time (sec): 159.02 - samples/sec: 3766.92 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:49:47,775 epoch 23 - iter 351/395 - loss 0.13801269 - time (sec): 177.81 - samples/sec: 3789.01 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:50:07,046 epoch 23 - iter 390/395 - loss 0.13865435 - time (sec): 197.08 - samples/sec: 3797.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:50:09,219 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:50:09,221 EPOCH 23 done: loss 0.1387 - lr: 0.100000\n",
            "2024-01-22 10:50:09,222  - 0 epochs without improvement\n",
            "2024-01-22 10:50:09,224 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:50:09,225 train mode resetting embeddings\n",
            "2024-01-22 10:50:09,226 train mode resetting embeddings\n",
            "2024-01-22 10:50:28,348 epoch 24 - iter 39/395 - loss 0.14083353 - time (sec): 19.12 - samples/sec: 3850.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:50:51,095 epoch 24 - iter 78/395 - loss 0.13633230 - time (sec): 41.87 - samples/sec: 3626.15 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:51:11,250 epoch 24 - iter 117/395 - loss 0.13596509 - time (sec): 62.02 - samples/sec: 3659.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:51:31,690 epoch 24 - iter 156/395 - loss 0.13741645 - time (sec): 82.46 - samples/sec: 3655.88 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:51:54,212 epoch 24 - iter 195/395 - loss 0.13755771 - time (sec): 104.98 - samples/sec: 3590.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:52:13,348 epoch 24 - iter 234/395 - loss 0.13701307 - time (sec): 124.12 - samples/sec: 3649.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:52:32,030 epoch 24 - iter 273/395 - loss 0.13843573 - time (sec): 142.80 - samples/sec: 3692.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:52:50,735 epoch 24 - iter 312/395 - loss 0.13812206 - time (sec): 161.51 - samples/sec: 3721.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:53:10,164 epoch 24 - iter 351/395 - loss 0.13832980 - time (sec): 180.94 - samples/sec: 3731.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:53:28,435 epoch 24 - iter 390/395 - loss 0.13828758 - time (sec): 199.21 - samples/sec: 3755.21 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:53:30,686 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:53:30,688 EPOCH 24 done: loss 0.1381 - lr: 0.100000\n",
            "2024-01-22 10:53:30,689  - 0 epochs without improvement\n",
            "2024-01-22 10:53:30,691 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:53:30,693 train mode resetting embeddings\n",
            "2024-01-22 10:53:30,694 train mode resetting embeddings\n",
            "2024-01-22 10:53:50,086 epoch 25 - iter 39/395 - loss 0.13511205 - time (sec): 19.39 - samples/sec: 3852.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:54:12,567 epoch 25 - iter 78/395 - loss 0.13475761 - time (sec): 41.87 - samples/sec: 3612.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:54:31,862 epoch 25 - iter 117/395 - loss 0.13724667 - time (sec): 61.17 - samples/sec: 3693.77 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:54:50,531 epoch 25 - iter 156/395 - loss 0.13691132 - time (sec): 79.84 - samples/sec: 3761.88 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:55:09,877 epoch 25 - iter 195/395 - loss 0.13634705 - time (sec): 99.18 - samples/sec: 3770.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:55:29,381 epoch 25 - iter 234/395 - loss 0.13683067 - time (sec): 118.69 - samples/sec: 3772.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:55:49,461 epoch 25 - iter 273/395 - loss 0.13675055 - time (sec): 138.77 - samples/sec: 3765.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:56:08,471 epoch 25 - iter 312/395 - loss 0.13652967 - time (sec): 157.78 - samples/sec: 3783.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:56:27,765 epoch 25 - iter 351/395 - loss 0.13766769 - time (sec): 177.07 - samples/sec: 3794.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:56:49,494 epoch 25 - iter 390/395 - loss 0.13764376 - time (sec): 198.80 - samples/sec: 3762.66 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:56:51,959 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:56:51,961 EPOCH 25 done: loss 0.1376 - lr: 0.100000\n",
            "2024-01-22 10:56:51,963  - 0 epochs without improvement\n",
            "2024-01-22 10:56:51,964 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 10:56:51,966 train mode resetting embeddings\n",
            "2024-01-22 10:56:51,967 train mode resetting embeddings\n",
            "2024-01-22 10:57:13,195 epoch 26 - iter 39/395 - loss 0.13431213 - time (sec): 21.23 - samples/sec: 3515.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:57:32,482 epoch 26 - iter 78/395 - loss 0.13403921 - time (sec): 40.51 - samples/sec: 3682.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:57:53,111 epoch 26 - iter 117/395 - loss 0.13620050 - time (sec): 61.14 - samples/sec: 3661.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:58:11,440 epoch 26 - iter 156/395 - loss 0.13679034 - time (sec): 79.47 - samples/sec: 3750.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:58:33,436 epoch 26 - iter 195/395 - loss 0.13843399 - time (sec): 101.47 - samples/sec: 3689.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:58:53,563 epoch 26 - iter 234/395 - loss 0.13898386 - time (sec): 121.59 - samples/sec: 3697.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:59:12,593 epoch 26 - iter 273/395 - loss 0.13868585 - time (sec): 140.62 - samples/sec: 3730.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:59:36,121 epoch 26 - iter 312/395 - loss 0.13838296 - time (sec): 164.15 - samples/sec: 3655.84 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 10:59:54,713 epoch 26 - iter 351/395 - loss 0.13796567 - time (sec): 182.74 - samples/sec: 3689.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:00:13,825 epoch 26 - iter 390/395 - loss 0.13775130 - time (sec): 201.86 - samples/sec: 3706.38 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:00:15,812 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:00:15,814 EPOCH 26 done: loss 0.1380 - lr: 0.100000\n",
            "2024-01-22 11:00:15,815  - 1 epochs without improvement\n",
            "2024-01-22 11:00:15,817 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:00:15,818 train mode resetting embeddings\n",
            "2024-01-22 11:00:15,819 train mode resetting embeddings\n",
            "2024-01-22 11:00:34,503 epoch 27 - iter 39/395 - loss 0.13618922 - time (sec): 18.68 - samples/sec: 3897.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:00:54,006 epoch 27 - iter 78/395 - loss 0.13396207 - time (sec): 38.18 - samples/sec: 3861.65 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:01:13,826 epoch 27 - iter 117/395 - loss 0.13603510 - time (sec): 58.00 - samples/sec: 3850.93 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:01:32,970 epoch 27 - iter 156/395 - loss 0.13509307 - time (sec): 77.15 - samples/sec: 3870.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:01:54,073 epoch 27 - iter 195/395 - loss 0.13615668 - time (sec): 98.25 - samples/sec: 3813.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:02:18,637 epoch 27 - iter 234/395 - loss 0.13662365 - time (sec): 122.81 - samples/sec: 3660.99 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:02:37,969 epoch 27 - iter 273/395 - loss 0.13598078 - time (sec): 142.15 - samples/sec: 3684.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:02:57,474 epoch 27 - iter 312/395 - loss 0.13530427 - time (sec): 161.65 - samples/sec: 3695.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:03:16,984 epoch 27 - iter 351/395 - loss 0.13661218 - time (sec): 181.16 - samples/sec: 3716.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:03:35,793 epoch 27 - iter 390/395 - loss 0.13639031 - time (sec): 199.97 - samples/sec: 3741.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:03:37,784 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:03:37,785 EPOCH 27 done: loss 0.1363 - lr: 0.100000\n",
            "2024-01-22 11:03:37,786  - 0 epochs without improvement\n",
            "2024-01-22 11:03:37,789 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:03:37,790 train mode resetting embeddings\n",
            "2024-01-22 11:03:37,793 train mode resetting embeddings\n",
            "2024-01-22 11:03:57,843 epoch 28 - iter 39/395 - loss 0.13310058 - time (sec): 20.05 - samples/sec: 3760.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:04:20,484 epoch 28 - iter 78/395 - loss 0.13502613 - time (sec): 42.69 - samples/sec: 3560.83 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:04:40,137 epoch 28 - iter 117/395 - loss 0.13400440 - time (sec): 62.34 - samples/sec: 3644.54 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:05:01,051 epoch 28 - iter 156/395 - loss 0.13473740 - time (sec): 83.26 - samples/sec: 3611.09 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:05:20,726 epoch 28 - iter 195/395 - loss 0.13461325 - time (sec): 102.93 - samples/sec: 3650.93 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:05:41,148 epoch 28 - iter 234/395 - loss 0.13430398 - time (sec): 123.35 - samples/sec: 3658.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:06:00,503 epoch 28 - iter 273/395 - loss 0.13447771 - time (sec): 142.71 - samples/sec: 3691.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:06:19,678 epoch 28 - iter 312/395 - loss 0.13436737 - time (sec): 161.88 - samples/sec: 3714.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:06:37,139 epoch 28 - iter 351/395 - loss 0.13495650 - time (sec): 179.35 - samples/sec: 3753.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:06:55,788 epoch 28 - iter 390/395 - loss 0.13485014 - time (sec): 197.99 - samples/sec: 3777.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:06:58,380 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:06:58,382 EPOCH 28 done: loss 0.1348 - lr: 0.100000\n",
            "2024-01-22 11:06:58,383  - 0 epochs without improvement\n",
            "2024-01-22 11:06:58,385 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:06:58,387 train mode resetting embeddings\n",
            "2024-01-22 11:06:58,388 train mode resetting embeddings\n",
            "2024-01-22 11:07:19,388 epoch 29 - iter 39/395 - loss 0.13851120 - time (sec): 21.00 - samples/sec: 3525.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:07:38,366 epoch 29 - iter 78/395 - loss 0.13546106 - time (sec): 39.98 - samples/sec: 3706.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:07:57,974 epoch 29 - iter 117/395 - loss 0.13316775 - time (sec): 59.59 - samples/sec: 3758.51 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:08:19,328 epoch 29 - iter 156/395 - loss 0.13400849 - time (sec): 80.94 - samples/sec: 3703.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:08:37,427 epoch 29 - iter 195/395 - loss 0.13494147 - time (sec): 99.04 - samples/sec: 3769.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:08:57,609 epoch 29 - iter 234/395 - loss 0.13519245 - time (sec): 119.22 - samples/sec: 3766.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:09:16,056 epoch 29 - iter 273/395 - loss 0.13554338 - time (sec): 137.67 - samples/sec: 3796.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:09:36,075 epoch 29 - iter 312/395 - loss 0.13499493 - time (sec): 157.69 - samples/sec: 3794.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:09:58,021 epoch 29 - iter 351/395 - loss 0.13492082 - time (sec): 179.63 - samples/sec: 3749.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:10:17,842 epoch 29 - iter 390/395 - loss 0.13456574 - time (sec): 199.45 - samples/sec: 3754.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:10:19,746 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:10:19,748 EPOCH 29 done: loss 0.1347 - lr: 0.100000\n",
            "2024-01-22 11:10:19,750  - 0 epochs without improvement\n",
            "2024-01-22 11:10:19,751 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:10:19,752 train mode resetting embeddings\n",
            "2024-01-22 11:10:19,753 train mode resetting embeddings\n",
            "2024-01-22 11:10:38,072 epoch 30 - iter 39/395 - loss 0.13967690 - time (sec): 18.32 - samples/sec: 4008.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:10:56,526 epoch 30 - iter 78/395 - loss 0.13488636 - time (sec): 36.77 - samples/sec: 3990.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:11:18,351 epoch 30 - iter 117/395 - loss 0.13498773 - time (sec): 58.59 - samples/sec: 3802.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:11:37,984 epoch 30 - iter 156/395 - loss 0.13347139 - time (sec): 78.23 - samples/sec: 3808.37 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:11:56,020 epoch 30 - iter 195/395 - loss 0.13436803 - time (sec): 96.26 - samples/sec: 3863.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:12:15,559 epoch 30 - iter 234/395 - loss 0.13380871 - time (sec): 115.80 - samples/sec: 3852.15 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:12:39,607 epoch 30 - iter 273/395 - loss 0.13342197 - time (sec): 139.85 - samples/sec: 3741.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:12:59,671 epoch 30 - iter 312/395 - loss 0.13351166 - time (sec): 159.91 - samples/sec: 3744.78 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:13:18,600 epoch 30 - iter 351/395 - loss 0.13404000 - time (sec): 178.84 - samples/sec: 3764.46 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:13:37,180 epoch 30 - iter 390/395 - loss 0.13387971 - time (sec): 197.42 - samples/sec: 3788.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:13:39,331 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:13:39,333 EPOCH 30 done: loss 0.1338 - lr: 0.100000\n",
            "2024-01-22 11:13:39,335  - 0 epochs without improvement\n",
            "2024-01-22 11:13:39,336 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:13:39,337 train mode resetting embeddings\n",
            "2024-01-22 11:13:39,338 train mode resetting embeddings\n",
            "2024-01-22 11:14:01,290 epoch 31 - iter 39/395 - loss 0.13485832 - time (sec): 21.95 - samples/sec: 3461.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:14:21,642 epoch 31 - iter 78/395 - loss 0.13296366 - time (sec): 42.30 - samples/sec: 3580.23 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:14:41,185 epoch 31 - iter 117/395 - loss 0.13364195 - time (sec): 61.84 - samples/sec: 3654.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:14:59,907 epoch 31 - iter 156/395 - loss 0.13398139 - time (sec): 80.57 - samples/sec: 3715.93 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:15:22,055 epoch 31 - iter 195/395 - loss 0.13313408 - time (sec): 102.71 - samples/sec: 3657.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:15:41,310 epoch 31 - iter 234/395 - loss 0.13334541 - time (sec): 121.97 - samples/sec: 3694.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:15:59,948 epoch 31 - iter 273/395 - loss 0.13285326 - time (sec): 140.61 - samples/sec: 3733.77 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:16:19,213 epoch 31 - iter 312/395 - loss 0.13278426 - time (sec): 159.87 - samples/sec: 3747.83 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:16:39,428 epoch 31 - iter 351/395 - loss 0.13249851 - time (sec): 180.09 - samples/sec: 3743.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:16:58,017 epoch 31 - iter 390/395 - loss 0.13217450 - time (sec): 198.68 - samples/sec: 3766.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:17:00,055 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:17:00,057 EPOCH 31 done: loss 0.1321 - lr: 0.100000\n",
            "2024-01-22 11:17:00,059  - 0 epochs without improvement\n",
            "2024-01-22 11:17:00,060 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:17:00,061 train mode resetting embeddings\n",
            "2024-01-22 11:17:00,063 train mode resetting embeddings\n",
            "2024-01-22 11:17:19,866 epoch 32 - iter 39/395 - loss 0.13556383 - time (sec): 19.80 - samples/sec: 3812.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:17:38,683 epoch 32 - iter 78/395 - loss 0.13534279 - time (sec): 38.62 - samples/sec: 3856.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:18:00,604 epoch 32 - iter 117/395 - loss 0.13303452 - time (sec): 60.54 - samples/sec: 3698.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:18:23,236 epoch 32 - iter 156/395 - loss 0.13217980 - time (sec): 83.17 - samples/sec: 3620.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:18:41,987 epoch 32 - iter 195/395 - loss 0.13231808 - time (sec): 101.92 - samples/sec: 3672.90 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:19:00,819 epoch 32 - iter 234/395 - loss 0.13254656 - time (sec): 120.75 - samples/sec: 3712.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:19:19,974 epoch 32 - iter 273/395 - loss 0.13246909 - time (sec): 139.91 - samples/sec: 3733.77 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:19:40,471 epoch 32 - iter 312/395 - loss 0.13204187 - time (sec): 160.41 - samples/sec: 3722.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:19:59,880 epoch 32 - iter 351/395 - loss 0.13233562 - time (sec): 179.81 - samples/sec: 3745.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:20:18,356 epoch 32 - iter 390/395 - loss 0.13208824 - time (sec): 198.29 - samples/sec: 3772.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:20:20,430 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:20:20,432 EPOCH 32 done: loss 0.1321 - lr: 0.100000\n",
            "2024-01-22 11:20:20,434  - 0 epochs without improvement\n",
            "2024-01-22 11:20:20,436 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:20:20,438 train mode resetting embeddings\n",
            "2024-01-22 11:20:20,439 train mode resetting embeddings\n",
            "2024-01-22 11:20:41,817 epoch 33 - iter 39/395 - loss 0.13189947 - time (sec): 21.38 - samples/sec: 3521.90 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:21:02,070 epoch 33 - iter 78/395 - loss 0.13068180 - time (sec): 41.63 - samples/sec: 3632.01 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:21:21,676 epoch 33 - iter 117/395 - loss 0.12951014 - time (sec): 61.24 - samples/sec: 3682.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:21:43,607 epoch 33 - iter 156/395 - loss 0.13047872 - time (sec): 83.17 - samples/sec: 3626.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:22:02,732 epoch 33 - iter 195/395 - loss 0.13038693 - time (sec): 102.29 - samples/sec: 3680.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:22:21,585 epoch 33 - iter 234/395 - loss 0.13114286 - time (sec): 121.14 - samples/sec: 3714.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:22:40,861 epoch 33 - iter 273/395 - loss 0.13167845 - time (sec): 140.42 - samples/sec: 3739.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:22:59,384 epoch 33 - iter 312/395 - loss 0.13169256 - time (sec): 158.94 - samples/sec: 3767.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:23:20,029 epoch 33 - iter 351/395 - loss 0.13202333 - time (sec): 179.59 - samples/sec: 3745.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:23:41,840 epoch 33 - iter 390/395 - loss 0.13161393 - time (sec): 201.40 - samples/sec: 3714.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:23:43,846 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:23:43,847 EPOCH 33 done: loss 0.1316 - lr: 0.100000\n",
            "2024-01-22 11:23:43,849  - 0 epochs without improvement\n",
            "2024-01-22 11:23:43,851 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:23:43,853 train mode resetting embeddings\n",
            "2024-01-22 11:23:43,853 train mode resetting embeddings\n",
            "2024-01-22 11:24:03,486 epoch 34 - iter 39/395 - loss 0.12783462 - time (sec): 19.63 - samples/sec: 3812.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:24:22,294 epoch 34 - iter 78/395 - loss 0.12918524 - time (sec): 38.44 - samples/sec: 3849.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:24:41,590 epoch 34 - iter 117/395 - loss 0.12947140 - time (sec): 57.74 - samples/sec: 3872.92 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:25:02,591 epoch 34 - iter 156/395 - loss 0.13050113 - time (sec): 78.74 - samples/sec: 3801.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:25:21,588 epoch 34 - iter 195/395 - loss 0.13101440 - time (sec): 97.73 - samples/sec: 3828.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:25:41,067 epoch 34 - iter 234/395 - loss 0.13227014 - time (sec): 117.21 - samples/sec: 3828.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:26:01,472 epoch 34 - iter 273/395 - loss 0.13158169 - time (sec): 137.62 - samples/sec: 3795.15 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:26:20,352 epoch 34 - iter 312/395 - loss 0.13174870 - time (sec): 156.50 - samples/sec: 3810.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:26:39,309 epoch 34 - iter 351/395 - loss 0.13178211 - time (sec): 175.45 - samples/sec: 3822.23 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:26:59,038 epoch 34 - iter 390/395 - loss 0.13200600 - time (sec): 195.18 - samples/sec: 3824.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:27:04,292 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:27:04,294 EPOCH 34 done: loss 0.1322 - lr: 0.100000\n",
            "2024-01-22 11:27:04,295  - 1 epochs without improvement\n",
            "2024-01-22 11:27:04,297 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:27:04,298 train mode resetting embeddings\n",
            "2024-01-22 11:27:04,299 train mode resetting embeddings\n",
            "2024-01-22 11:27:23,999 epoch 35 - iter 39/395 - loss 0.13436359 - time (sec): 19.70 - samples/sec: 3866.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:27:45,464 epoch 35 - iter 78/395 - loss 0.13334597 - time (sec): 41.16 - samples/sec: 3694.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:28:04,192 epoch 35 - iter 117/395 - loss 0.13336197 - time (sec): 59.89 - samples/sec: 3786.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:28:23,325 epoch 35 - iter 156/395 - loss 0.13290734 - time (sec): 79.02 - samples/sec: 3820.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:28:44,444 epoch 35 - iter 195/395 - loss 0.13156787 - time (sec): 100.14 - samples/sec: 3747.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:29:03,438 epoch 35 - iter 234/395 - loss 0.13118142 - time (sec): 119.14 - samples/sec: 3771.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:29:23,586 epoch 35 - iter 273/395 - loss 0.13056510 - time (sec): 139.29 - samples/sec: 3778.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:29:42,085 epoch 35 - iter 312/395 - loss 0.13071132 - time (sec): 157.78 - samples/sec: 3798.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:30:00,337 epoch 35 - iter 351/395 - loss 0.13098178 - time (sec): 176.04 - samples/sec: 3821.54 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:30:20,595 epoch 35 - iter 390/395 - loss 0.13090759 - time (sec): 196.29 - samples/sec: 3809.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:30:22,723 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:30:22,724 EPOCH 35 done: loss 0.1309 - lr: 0.100000\n",
            "2024-01-22 11:30:22,725  - 0 epochs without improvement\n",
            "2024-01-22 11:30:22,729 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:30:22,730 train mode resetting embeddings\n",
            "2024-01-22 11:30:22,731 train mode resetting embeddings\n",
            "2024-01-22 11:30:40,957 epoch 36 - iter 39/395 - loss 0.12597580 - time (sec): 18.22 - samples/sec: 4082.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:31:02,331 epoch 36 - iter 78/395 - loss 0.13070811 - time (sec): 39.60 - samples/sec: 3830.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:31:23,899 epoch 36 - iter 117/395 - loss 0.12935929 - time (sec): 61.17 - samples/sec: 3694.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:31:45,115 epoch 36 - iter 156/395 - loss 0.12991193 - time (sec): 82.38 - samples/sec: 3660.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:32:03,892 epoch 36 - iter 195/395 - loss 0.13023747 - time (sec): 101.16 - samples/sec: 3702.61 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:32:23,674 epoch 36 - iter 234/395 - loss 0.12998349 - time (sec): 120.94 - samples/sec: 3704.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:32:42,747 epoch 36 - iter 273/395 - loss 0.12948821 - time (sec): 140.02 - samples/sec: 3726.04 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:33:02,812 epoch 36 - iter 312/395 - loss 0.12956112 - time (sec): 160.08 - samples/sec: 3732.92 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:33:21,653 epoch 36 - iter 351/395 - loss 0.13036211 - time (sec): 178.92 - samples/sec: 3751.38 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:33:41,945 epoch 36 - iter 390/395 - loss 0.13026302 - time (sec): 199.21 - samples/sec: 3754.09 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:33:44,395 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:33:44,397 EPOCH 36 done: loss 0.1303 - lr: 0.100000\n",
            "2024-01-22 11:33:44,398  - 0 epochs without improvement\n",
            "2024-01-22 11:33:44,400 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:33:44,401 train mode resetting embeddings\n",
            "2024-01-22 11:33:44,402 train mode resetting embeddings\n",
            "2024-01-22 11:34:05,646 epoch 37 - iter 39/395 - loss 0.13317613 - time (sec): 21.24 - samples/sec: 3494.99 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:34:23,434 epoch 37 - iter 78/395 - loss 0.13133787 - time (sec): 39.03 - samples/sec: 3750.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:34:42,047 epoch 37 - iter 117/395 - loss 0.13255607 - time (sec): 57.64 - samples/sec: 3831.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:35:03,939 epoch 37 - iter 156/395 - loss 0.13252335 - time (sec): 79.54 - samples/sec: 3741.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:35:22,984 epoch 37 - iter 195/395 - loss 0.13182782 - time (sec): 98.58 - samples/sec: 3772.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:35:45,812 epoch 37 - iter 234/395 - loss 0.13081871 - time (sec): 121.41 - samples/sec: 3695.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:36:05,540 epoch 37 - iter 273/395 - loss 0.13075740 - time (sec): 141.14 - samples/sec: 3708.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:36:24,998 epoch 37 - iter 312/395 - loss 0.13017615 - time (sec): 160.60 - samples/sec: 3724.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:36:47,079 epoch 37 - iter 351/395 - loss 0.13001184 - time (sec): 182.68 - samples/sec: 3693.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:37:06,587 epoch 37 - iter 390/395 - loss 0.12981699 - time (sec): 202.18 - samples/sec: 3701.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:37:08,570 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:37:08,572 EPOCH 37 done: loss 0.1299 - lr: 0.100000\n",
            "2024-01-22 11:37:08,573  - 0 epochs without improvement\n",
            "2024-01-22 11:37:08,575 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:37:08,576 train mode resetting embeddings\n",
            "2024-01-22 11:37:08,577 train mode resetting embeddings\n",
            "2024-01-22 11:37:26,825 epoch 38 - iter 39/395 - loss 0.12935776 - time (sec): 18.25 - samples/sec: 4013.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:37:46,930 epoch 38 - iter 78/395 - loss 0.12655637 - time (sec): 38.35 - samples/sec: 3852.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:38:07,243 epoch 38 - iter 117/395 - loss 0.12648220 - time (sec): 58.66 - samples/sec: 3802.54 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:38:26,882 epoch 38 - iter 156/395 - loss 0.12725847 - time (sec): 78.30 - samples/sec: 3808.01 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:38:49,113 epoch 38 - iter 195/395 - loss 0.12635336 - time (sec): 100.54 - samples/sec: 3732.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:39:08,737 epoch 38 - iter 234/395 - loss 0.12724197 - time (sec): 120.16 - samples/sec: 3743.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:39:30,352 epoch 38 - iter 273/395 - loss 0.12825545 - time (sec): 141.77 - samples/sec: 3700.54 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:39:49,131 epoch 38 - iter 312/395 - loss 0.12830629 - time (sec): 160.55 - samples/sec: 3726.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:40:07,901 epoch 38 - iter 351/395 - loss 0.12836109 - time (sec): 179.32 - samples/sec: 3757.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:40:27,330 epoch 38 - iter 390/395 - loss 0.12879720 - time (sec): 198.75 - samples/sec: 3767.64 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:40:29,107 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:40:29,109 EPOCH 38 done: loss 0.1289 - lr: 0.100000\n",
            "2024-01-22 11:40:29,110  - 0 epochs without improvement\n",
            "2024-01-22 11:40:29,112 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:40:29,113 train mode resetting embeddings\n",
            "2024-01-22 11:40:29,115 train mode resetting embeddings\n",
            "2024-01-22 11:40:48,999 epoch 39 - iter 39/395 - loss 0.12423707 - time (sec): 19.88 - samples/sec: 3764.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:41:07,179 epoch 39 - iter 78/395 - loss 0.12863576 - time (sec): 38.06 - samples/sec: 3912.39 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:41:26,599 epoch 39 - iter 117/395 - loss 0.12625290 - time (sec): 57.48 - samples/sec: 3886.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:41:46,100 epoch 39 - iter 156/395 - loss 0.12708135 - time (sec): 76.98 - samples/sec: 3882.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:42:12,373 epoch 39 - iter 195/395 - loss 0.12836344 - time (sec): 103.26 - samples/sec: 3642.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:42:30,910 epoch 39 - iter 234/395 - loss 0.12856557 - time (sec): 121.79 - samples/sec: 3695.61 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:42:49,291 epoch 39 - iter 273/395 - loss 0.12849665 - time (sec): 140.18 - samples/sec: 3735.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:43:07,547 epoch 39 - iter 312/395 - loss 0.12884879 - time (sec): 158.43 - samples/sec: 3777.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:43:27,168 epoch 39 - iter 351/395 - loss 0.12844051 - time (sec): 178.05 - samples/sec: 3784.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:43:45,951 epoch 39 - iter 390/395 - loss 0.12869153 - time (sec): 196.83 - samples/sec: 3799.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:43:48,255 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:43:48,257 EPOCH 39 done: loss 0.1287 - lr: 0.100000\n",
            "2024-01-22 11:43:48,258  - 0 epochs without improvement\n",
            "2024-01-22 11:43:48,260 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:43:48,262 train mode resetting embeddings\n",
            "2024-01-22 11:43:48,263 train mode resetting embeddings\n",
            "2024-01-22 11:44:06,930 epoch 40 - iter 39/395 - loss 0.12928850 - time (sec): 18.67 - samples/sec: 4017.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:44:25,834 epoch 40 - iter 78/395 - loss 0.12791571 - time (sec): 37.57 - samples/sec: 3984.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:44:49,097 epoch 40 - iter 117/395 - loss 0.12882113 - time (sec): 60.83 - samples/sec: 3691.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:45:08,725 epoch 40 - iter 156/395 - loss 0.12990755 - time (sec): 80.46 - samples/sec: 3715.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:45:26,856 epoch 40 - iter 195/395 - loss 0.12949257 - time (sec): 98.59 - samples/sec: 3781.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:45:45,698 epoch 40 - iter 234/395 - loss 0.12847226 - time (sec): 117.43 - samples/sec: 3803.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:46:08,954 epoch 40 - iter 273/395 - loss 0.12759589 - time (sec): 140.69 - samples/sec: 3734.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:46:27,754 epoch 40 - iter 312/395 - loss 0.12802646 - time (sec): 159.49 - samples/sec: 3764.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:46:47,187 epoch 40 - iter 351/395 - loss 0.12837219 - time (sec): 178.92 - samples/sec: 3771.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:47:05,269 epoch 40 - iter 390/395 - loss 0.12846250 - time (sec): 197.01 - samples/sec: 3793.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:47:07,785 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:47:07,787 EPOCH 40 done: loss 0.1284 - lr: 0.100000\n",
            "2024-01-22 11:47:07,788  - 0 epochs without improvement\n",
            "2024-01-22 11:47:07,790 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:47:07,792 train mode resetting embeddings\n",
            "2024-01-22 11:47:07,793 train mode resetting embeddings\n",
            "2024-01-22 11:47:31,966 epoch 41 - iter 39/395 - loss 0.12146250 - time (sec): 24.17 - samples/sec: 3219.09 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:47:50,983 epoch 41 - iter 78/395 - loss 0.12618492 - time (sec): 43.19 - samples/sec: 3506.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:48:09,117 epoch 41 - iter 117/395 - loss 0.12679066 - time (sec): 61.32 - samples/sec: 3649.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:48:28,510 epoch 41 - iter 156/395 - loss 0.12642476 - time (sec): 80.71 - samples/sec: 3691.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:48:48,377 epoch 41 - iter 195/395 - loss 0.12544948 - time (sec): 100.58 - samples/sec: 3723.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:49:07,156 epoch 41 - iter 234/395 - loss 0.12532648 - time (sec): 119.36 - samples/sec: 3756.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:49:28,993 epoch 41 - iter 273/395 - loss 0.12701078 - time (sec): 141.20 - samples/sec: 3713.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:49:51,220 epoch 41 - iter 312/395 - loss 0.12699983 - time (sec): 163.43 - samples/sec: 3662.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:50:09,402 epoch 41 - iter 351/395 - loss 0.12692770 - time (sec): 181.61 - samples/sec: 3705.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:50:27,820 epoch 41 - iter 390/395 - loss 0.12694086 - time (sec): 200.03 - samples/sec: 3740.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:50:29,971 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:50:29,973 EPOCH 41 done: loss 0.1270 - lr: 0.100000\n",
            "2024-01-22 11:50:29,974  - 0 epochs without improvement\n",
            "2024-01-22 11:50:29,976 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:50:29,978 train mode resetting embeddings\n",
            "2024-01-22 11:50:29,979 train mode resetting embeddings\n",
            "2024-01-22 11:50:49,206 epoch 42 - iter 39/395 - loss 0.12601716 - time (sec): 19.23 - samples/sec: 3923.39 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:51:06,884 epoch 42 - iter 78/395 - loss 0.12453836 - time (sec): 36.90 - samples/sec: 4007.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:51:24,889 epoch 42 - iter 117/395 - loss 0.12630995 - time (sec): 54.91 - samples/sec: 4040.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:51:45,760 epoch 42 - iter 156/395 - loss 0.12704648 - time (sec): 75.78 - samples/sec: 3934.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:52:05,912 epoch 42 - iter 195/395 - loss 0.12758314 - time (sec): 95.93 - samples/sec: 3893.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:52:27,695 epoch 42 - iter 234/395 - loss 0.12746939 - time (sec): 117.71 - samples/sec: 3808.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:52:47,499 epoch 42 - iter 273/395 - loss 0.12752481 - time (sec): 137.52 - samples/sec: 3810.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:53:07,220 epoch 42 - iter 312/395 - loss 0.12731214 - time (sec): 157.24 - samples/sec: 3813.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:53:28,644 epoch 42 - iter 351/395 - loss 0.12749179 - time (sec): 178.66 - samples/sec: 3772.58 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:53:47,709 epoch 42 - iter 390/395 - loss 0.12771523 - time (sec): 197.73 - samples/sec: 3783.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:53:49,861 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:53:49,863 EPOCH 42 done: loss 0.1275 - lr: 0.100000\n",
            "2024-01-22 11:53:49,864  - 1 epochs without improvement\n",
            "2024-01-22 11:53:49,866 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:53:49,867 train mode resetting embeddings\n",
            "2024-01-22 11:53:49,868 train mode resetting embeddings\n",
            "2024-01-22 11:54:08,829 epoch 43 - iter 39/395 - loss 0.12570316 - time (sec): 18.96 - samples/sec: 3930.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:54:26,601 epoch 43 - iter 78/395 - loss 0.12667230 - time (sec): 36.73 - samples/sec: 4021.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:54:45,164 epoch 43 - iter 117/395 - loss 0.12578726 - time (sec): 55.29 - samples/sec: 3996.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:55:07,959 epoch 43 - iter 156/395 - loss 0.12543696 - time (sec): 78.09 - samples/sec: 3802.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:55:27,878 epoch 43 - iter 195/395 - loss 0.12525891 - time (sec): 98.01 - samples/sec: 3785.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:55:46,619 epoch 43 - iter 234/395 - loss 0.12627093 - time (sec): 116.75 - samples/sec: 3826.87 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:56:06,835 epoch 43 - iter 273/395 - loss 0.12664590 - time (sec): 136.97 - samples/sec: 3826.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:56:26,108 epoch 43 - iter 312/395 - loss 0.12637902 - time (sec): 156.24 - samples/sec: 3832.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:56:47,970 epoch 43 - iter 351/395 - loss 0.12569534 - time (sec): 178.10 - samples/sec: 3791.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:57:06,435 epoch 43 - iter 390/395 - loss 0.12549499 - time (sec): 196.57 - samples/sec: 3806.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:57:08,553 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:57:08,555 EPOCH 43 done: loss 0.1258 - lr: 0.100000\n",
            "2024-01-22 11:57:08,557  - 0 epochs without improvement\n",
            "2024-01-22 11:57:08,558 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 11:57:08,561 train mode resetting embeddings\n",
            "2024-01-22 11:57:08,562 train mode resetting embeddings\n",
            "2024-01-22 11:57:29,907 epoch 44 - iter 39/395 - loss 0.12463531 - time (sec): 21.34 - samples/sec: 3462.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:57:48,465 epoch 44 - iter 78/395 - loss 0.12303196 - time (sec): 39.90 - samples/sec: 3699.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:58:06,983 epoch 44 - iter 117/395 - loss 0.12295568 - time (sec): 58.42 - samples/sec: 3772.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:58:25,768 epoch 44 - iter 156/395 - loss 0.12497431 - time (sec): 77.20 - samples/sec: 3823.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:58:45,476 epoch 44 - iter 195/395 - loss 0.12539613 - time (sec): 96.91 - samples/sec: 3822.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:59:08,261 epoch 44 - iter 234/395 - loss 0.12453513 - time (sec): 119.70 - samples/sec: 3738.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:59:28,077 epoch 44 - iter 273/395 - loss 0.12523755 - time (sec): 139.51 - samples/sec: 3753.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 11:59:48,372 epoch 44 - iter 312/395 - loss 0.12518118 - time (sec): 159.81 - samples/sec: 3746.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:00:10,384 epoch 44 - iter 351/395 - loss 0.12489004 - time (sec): 181.82 - samples/sec: 3705.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:00:29,467 epoch 44 - iter 390/395 - loss 0.12538130 - time (sec): 200.90 - samples/sec: 3725.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:00:31,391 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:00:31,392 EPOCH 44 done: loss 0.1254 - lr: 0.100000\n",
            "2024-01-22 12:00:31,394  - 0 epochs without improvement\n",
            "2024-01-22 12:00:31,396 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:00:31,397 train mode resetting embeddings\n",
            "2024-01-22 12:00:31,398 train mode resetting embeddings\n",
            "2024-01-22 12:00:51,023 epoch 45 - iter 39/395 - loss 0.12480070 - time (sec): 19.62 - samples/sec: 3889.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:01:09,940 epoch 45 - iter 78/395 - loss 0.12508820 - time (sec): 38.54 - samples/sec: 3893.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:01:28,642 epoch 45 - iter 117/395 - loss 0.12503695 - time (sec): 57.24 - samples/sec: 3891.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:01:52,571 epoch 45 - iter 156/395 - loss 0.12558498 - time (sec): 81.17 - samples/sec: 3705.90 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:02:11,168 epoch 45 - iter 195/395 - loss 0.12488539 - time (sec): 99.77 - samples/sec: 3749.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:02:31,018 epoch 45 - iter 234/395 - loss 0.12546953 - time (sec): 119.62 - samples/sec: 3757.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:02:53,017 epoch 45 - iter 273/395 - loss 0.12605577 - time (sec): 141.62 - samples/sec: 3696.21 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:03:12,533 epoch 45 - iter 312/395 - loss 0.12608119 - time (sec): 161.13 - samples/sec: 3713.23 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:03:31,286 epoch 45 - iter 351/395 - loss 0.12644028 - time (sec): 179.89 - samples/sec: 3736.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:03:50,690 epoch 45 - iter 390/395 - loss 0.12603652 - time (sec): 199.29 - samples/sec: 3753.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:03:52,825 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:03:52,826 EPOCH 45 done: loss 0.1261 - lr: 0.100000\n",
            "2024-01-22 12:03:52,829  - 1 epochs without improvement\n",
            "2024-01-22 12:03:52,831 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:03:52,832 train mode resetting embeddings\n",
            "2024-01-22 12:03:52,833 train mode resetting embeddings\n",
            "2024-01-22 12:04:11,129 epoch 46 - iter 39/395 - loss 0.12561797 - time (sec): 18.29 - samples/sec: 4010.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:04:30,513 epoch 46 - iter 78/395 - loss 0.12484409 - time (sec): 37.68 - samples/sec: 3924.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:04:51,464 epoch 46 - iter 117/395 - loss 0.12415816 - time (sec): 58.63 - samples/sec: 3808.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:05:09,824 epoch 46 - iter 156/395 - loss 0.12575507 - time (sec): 76.99 - samples/sec: 3859.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:05:33,681 epoch 46 - iter 195/395 - loss 0.12728024 - time (sec): 100.85 - samples/sec: 3696.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:05:53,272 epoch 46 - iter 234/395 - loss 0.12700872 - time (sec): 120.44 - samples/sec: 3717.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:06:13,668 epoch 46 - iter 273/395 - loss 0.12631196 - time (sec): 140.83 - samples/sec: 3708.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:06:33,058 epoch 46 - iter 312/395 - loss 0.12661662 - time (sec): 160.22 - samples/sec: 3739.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:06:54,030 epoch 46 - iter 351/395 - loss 0.12612894 - time (sec): 181.20 - samples/sec: 3726.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:07:12,102 epoch 46 - iter 390/395 - loss 0.12611469 - time (sec): 199.27 - samples/sec: 3758.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:07:13,980 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:07:13,983 EPOCH 46 done: loss 0.1260 - lr: 0.100000\n",
            "2024-01-22 12:07:13,984  - 2 epochs without improvement\n",
            "2024-01-22 12:07:13,985 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:07:13,987 train mode resetting embeddings\n",
            "2024-01-22 12:07:13,988 train mode resetting embeddings\n",
            "2024-01-22 12:07:32,073 epoch 47 - iter 39/395 - loss 0.11710528 - time (sec): 18.08 - samples/sec: 4022.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:07:51,702 epoch 47 - iter 78/395 - loss 0.12099107 - time (sec): 37.71 - samples/sec: 3944.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:08:12,593 epoch 47 - iter 117/395 - loss 0.12418281 - time (sec): 58.60 - samples/sec: 3811.64 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:08:31,041 epoch 47 - iter 156/395 - loss 0.12391779 - time (sec): 77.05 - samples/sec: 3846.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:08:51,462 epoch 47 - iter 195/395 - loss 0.12374538 - time (sec): 97.47 - samples/sec: 3817.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:09:09,941 epoch 47 - iter 234/395 - loss 0.12404728 - time (sec): 115.95 - samples/sec: 3844.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:09:30,426 epoch 47 - iter 273/395 - loss 0.12512924 - time (sec): 136.44 - samples/sec: 3822.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:09:49,322 epoch 47 - iter 312/395 - loss 0.12511485 - time (sec): 155.33 - samples/sec: 3840.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:10:08,750 epoch 47 - iter 351/395 - loss 0.12466730 - time (sec): 174.76 - samples/sec: 3842.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:10:31,545 epoch 47 - iter 390/395 - loss 0.12515445 - time (sec): 197.56 - samples/sec: 3786.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:10:33,763 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:10:33,764 EPOCH 47 done: loss 0.1253 - lr: 0.100000\n",
            "2024-01-22 12:10:33,766  - 0 epochs without improvement\n",
            "2024-01-22 12:10:33,768 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:10:33,769 train mode resetting embeddings\n",
            "2024-01-22 12:10:33,770 train mode resetting embeddings\n",
            "2024-01-22 12:10:54,514 epoch 48 - iter 39/395 - loss 0.12400934 - time (sec): 20.74 - samples/sec: 3494.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:11:17,818 epoch 48 - iter 78/395 - loss 0.12361513 - time (sec): 44.04 - samples/sec: 3408.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:11:36,147 epoch 48 - iter 117/395 - loss 0.12414871 - time (sec): 62.37 - samples/sec: 3591.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:11:54,320 epoch 48 - iter 156/395 - loss 0.12507851 - time (sec): 80.55 - samples/sec: 3680.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:12:14,356 epoch 48 - iter 195/395 - loss 0.12419404 - time (sec): 100.58 - samples/sec: 3707.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:12:33,835 epoch 48 - iter 234/395 - loss 0.12353626 - time (sec): 120.06 - samples/sec: 3724.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:12:51,997 epoch 48 - iter 273/395 - loss 0.12420296 - time (sec): 138.22 - samples/sec: 3775.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:13:12,204 epoch 48 - iter 312/395 - loss 0.12420658 - time (sec): 158.43 - samples/sec: 3771.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:13:35,451 epoch 48 - iter 351/395 - loss 0.12407968 - time (sec): 181.68 - samples/sec: 3707.56 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:13:54,608 epoch 48 - iter 390/395 - loss 0.12336303 - time (sec): 200.83 - samples/sec: 3724.23 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:13:56,632 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:13:56,634 EPOCH 48 done: loss 0.1233 - lr: 0.100000\n",
            "2024-01-22 12:13:56,635  - 0 epochs without improvement\n",
            "2024-01-22 12:13:56,637 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:13:56,639 train mode resetting embeddings\n",
            "2024-01-22 12:13:56,640 train mode resetting embeddings\n",
            "2024-01-22 12:14:15,424 epoch 49 - iter 39/395 - loss 0.12786889 - time (sec): 18.78 - samples/sec: 3968.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:14:38,292 epoch 49 - iter 78/395 - loss 0.12320577 - time (sec): 41.65 - samples/sec: 3619.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:14:57,450 epoch 49 - iter 117/395 - loss 0.12396361 - time (sec): 60.81 - samples/sec: 3718.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:15:16,200 epoch 49 - iter 156/395 - loss 0.12374114 - time (sec): 79.56 - samples/sec: 3773.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:15:35,646 epoch 49 - iter 195/395 - loss 0.12278948 - time (sec): 99.00 - samples/sec: 3787.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:15:56,723 epoch 49 - iter 234/395 - loss 0.12161090 - time (sec): 120.08 - samples/sec: 3748.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:16:18,717 epoch 49 - iter 273/395 - loss 0.12193999 - time (sec): 142.08 - samples/sec: 3693.21 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:16:37,607 epoch 49 - iter 312/395 - loss 0.12182037 - time (sec): 160.97 - samples/sec: 3712.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:16:55,994 epoch 49 - iter 351/395 - loss 0.12285902 - time (sec): 179.35 - samples/sec: 3751.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:17:14,613 epoch 49 - iter 390/395 - loss 0.12374578 - time (sec): 197.97 - samples/sec: 3777.38 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:17:16,929 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:17:16,930 EPOCH 49 done: loss 0.1238 - lr: 0.100000\n",
            "2024-01-22 12:17:16,932  - 1 epochs without improvement\n",
            "2024-01-22 12:17:16,935 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:17:16,936 train mode resetting embeddings\n",
            "2024-01-22 12:17:16,937 train mode resetting embeddings\n",
            "2024-01-22 12:17:35,519 epoch 50 - iter 39/395 - loss 0.12280389 - time (sec): 18.58 - samples/sec: 4031.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:17:55,048 epoch 50 - iter 78/395 - loss 0.12388572 - time (sec): 38.11 - samples/sec: 3929.62 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:18:13,332 epoch 50 - iter 117/395 - loss 0.12439324 - time (sec): 56.39 - samples/sec: 3960.62 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:18:34,663 epoch 50 - iter 156/395 - loss 0.12382462 - time (sec): 77.72 - samples/sec: 3829.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:18:54,217 epoch 50 - iter 195/395 - loss 0.12339953 - time (sec): 97.28 - samples/sec: 3837.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:19:13,042 epoch 50 - iter 234/395 - loss 0.12430661 - time (sec): 116.10 - samples/sec: 3858.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:19:34,142 epoch 50 - iter 273/395 - loss 0.12463632 - time (sec): 137.20 - samples/sec: 3816.61 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:19:53,740 epoch 50 - iter 312/395 - loss 0.12372986 - time (sec): 156.80 - samples/sec: 3815.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:20:12,327 epoch 50 - iter 351/395 - loss 0.12360346 - time (sec): 175.39 - samples/sec: 3828.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:20:32,875 epoch 50 - iter 390/395 - loss 0.12379310 - time (sec): 195.94 - samples/sec: 3816.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:20:35,185 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:20:35,187 EPOCH 50 done: loss 0.1236 - lr: 0.100000\n",
            "2024-01-22 12:20:35,188  - 2 epochs without improvement\n",
            "2024-01-22 12:20:35,191 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:20:35,192 train mode resetting embeddings\n",
            "2024-01-22 12:20:35,193 train mode resetting embeddings\n",
            "2024-01-22 12:20:53,398 epoch 51 - iter 39/395 - loss 0.11965633 - time (sec): 18.20 - samples/sec: 3947.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:21:14,435 epoch 51 - iter 78/395 - loss 0.11998256 - time (sec): 39.24 - samples/sec: 3717.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:21:32,772 epoch 51 - iter 117/395 - loss 0.12103291 - time (sec): 57.58 - samples/sec: 3824.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:21:54,836 epoch 51 - iter 156/395 - loss 0.12237038 - time (sec): 79.64 - samples/sec: 3736.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:22:15,083 epoch 51 - iter 195/395 - loss 0.12275094 - time (sec): 99.89 - samples/sec: 3749.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:22:33,844 epoch 51 - iter 234/395 - loss 0.12226402 - time (sec): 118.65 - samples/sec: 3782.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:22:52,372 epoch 51 - iter 273/395 - loss 0.12239936 - time (sec): 137.18 - samples/sec: 3815.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:23:11,161 epoch 51 - iter 312/395 - loss 0.12288155 - time (sec): 155.96 - samples/sec: 3829.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:23:30,524 epoch 51 - iter 351/395 - loss 0.12339155 - time (sec): 175.33 - samples/sec: 3829.04 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:23:54,109 epoch 51 - iter 390/395 - loss 0.12295518 - time (sec): 198.91 - samples/sec: 3761.53 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:23:56,207 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:23:56,208 EPOCH 51 done: loss 0.1230 - lr: 0.100000\n",
            "2024-01-22 12:23:56,210  - 0 epochs without improvement\n",
            "2024-01-22 12:23:56,212 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:23:56,214 train mode resetting embeddings\n",
            "2024-01-22 12:23:56,215 train mode resetting embeddings\n",
            "2024-01-22 12:24:16,208 epoch 52 - iter 39/395 - loss 0.12154640 - time (sec): 19.99 - samples/sec: 3771.87 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:24:38,687 epoch 52 - iter 78/395 - loss 0.11942222 - time (sec): 42.47 - samples/sec: 3567.37 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:24:57,143 epoch 52 - iter 117/395 - loss 0.11901848 - time (sec): 60.93 - samples/sec: 3691.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:25:16,930 epoch 52 - iter 156/395 - loss 0.12056289 - time (sec): 80.71 - samples/sec: 3724.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:25:35,983 epoch 52 - iter 195/395 - loss 0.12069857 - time (sec): 99.77 - samples/sec: 3770.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:25:54,959 epoch 52 - iter 234/395 - loss 0.12045395 - time (sec): 118.74 - samples/sec: 3803.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:26:15,466 epoch 52 - iter 273/395 - loss 0.12118430 - time (sec): 139.25 - samples/sec: 3785.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:26:36,186 epoch 52 - iter 312/395 - loss 0.12161838 - time (sec): 159.97 - samples/sec: 3754.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:26:55,164 epoch 52 - iter 351/395 - loss 0.12232577 - time (sec): 178.95 - samples/sec: 3776.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:27:13,188 epoch 52 - iter 390/395 - loss 0.12270179 - time (sec): 196.97 - samples/sec: 3799.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:27:15,209 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:27:15,211 EPOCH 52 done: loss 0.1227 - lr: 0.100000\n",
            "2024-01-22 12:27:15,212  - 0 epochs without improvement\n",
            "2024-01-22 12:27:15,215 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:27:15,216 train mode resetting embeddings\n",
            "2024-01-22 12:27:15,217 train mode resetting embeddings\n",
            "2024-01-22 12:27:34,472 epoch 53 - iter 39/395 - loss 0.11564239 - time (sec): 19.25 - samples/sec: 3890.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:27:52,972 epoch 53 - iter 78/395 - loss 0.12063857 - time (sec): 37.75 - samples/sec: 3941.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:28:11,518 epoch 53 - iter 117/395 - loss 0.11940716 - time (sec): 56.30 - samples/sec: 3939.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:28:32,288 epoch 53 - iter 156/395 - loss 0.12006390 - time (sec): 77.07 - samples/sec: 3877.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:28:53,372 epoch 53 - iter 195/395 - loss 0.12187831 - time (sec): 98.15 - samples/sec: 3792.40 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:29:12,862 epoch 53 - iter 234/395 - loss 0.12192836 - time (sec): 117.64 - samples/sec: 3804.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:29:33,534 epoch 53 - iter 273/395 - loss 0.12149392 - time (sec): 138.32 - samples/sec: 3784.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:29:52,664 epoch 53 - iter 312/395 - loss 0.12130339 - time (sec): 157.45 - samples/sec: 3792.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:30:11,405 epoch 53 - iter 351/395 - loss 0.12135340 - time (sec): 176.19 - samples/sec: 3805.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:30:32,078 epoch 53 - iter 390/395 - loss 0.12189587 - time (sec): 196.86 - samples/sec: 3794.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:30:37,131 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:30:37,133 EPOCH 53 done: loss 0.1221 - lr: 0.100000\n",
            "2024-01-22 12:30:37,134  - 0 epochs without improvement\n",
            "2024-01-22 12:30:37,136 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:30:37,137 train mode resetting embeddings\n",
            "2024-01-22 12:30:37,138 train mode resetting embeddings\n",
            "2024-01-22 12:30:55,714 epoch 54 - iter 39/395 - loss 0.12054265 - time (sec): 18.57 - samples/sec: 3951.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:31:15,217 epoch 54 - iter 78/395 - loss 0.12066316 - time (sec): 38.08 - samples/sec: 3888.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:31:37,632 epoch 54 - iter 117/395 - loss 0.12048421 - time (sec): 60.49 - samples/sec: 3685.58 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:31:56,840 epoch 54 - iter 156/395 - loss 0.12196428 - time (sec): 79.70 - samples/sec: 3727.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:32:16,177 epoch 54 - iter 195/395 - loss 0.12007734 - time (sec): 99.04 - samples/sec: 3756.48 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:32:38,938 epoch 54 - iter 234/395 - loss 0.12031406 - time (sec): 121.80 - samples/sec: 3694.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:32:57,456 epoch 54 - iter 273/395 - loss 0.12001604 - time (sec): 140.32 - samples/sec: 3728.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:33:16,989 epoch 54 - iter 312/395 - loss 0.12008587 - time (sec): 159.85 - samples/sec: 3741.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:33:36,701 epoch 54 - iter 351/395 - loss 0.12030496 - time (sec): 179.56 - samples/sec: 3752.77 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:33:55,496 epoch 54 - iter 390/395 - loss 0.12045307 - time (sec): 198.36 - samples/sec: 3770.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:33:57,818 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:33:57,819 EPOCH 54 done: loss 0.1204 - lr: 0.100000\n",
            "2024-01-22 12:33:57,821  - 0 epochs without improvement\n",
            "2024-01-22 12:33:57,823 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:33:57,825 train mode resetting embeddings\n",
            "2024-01-22 12:33:57,826 train mode resetting embeddings\n",
            "2024-01-22 12:34:19,358 epoch 55 - iter 39/395 - loss 0.12199827 - time (sec): 21.53 - samples/sec: 3474.72 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:34:38,010 epoch 55 - iter 78/395 - loss 0.12119713 - time (sec): 40.18 - samples/sec: 3711.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:34:57,017 epoch 55 - iter 117/395 - loss 0.11916180 - time (sec): 59.19 - samples/sec: 3764.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:35:15,953 epoch 55 - iter 156/395 - loss 0.11899144 - time (sec): 78.12 - samples/sec: 3812.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:35:34,762 epoch 55 - iter 195/395 - loss 0.11937482 - time (sec): 96.93 - samples/sec: 3837.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:35:56,989 epoch 55 - iter 234/395 - loss 0.12045863 - time (sec): 119.16 - samples/sec: 3762.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:36:16,164 epoch 55 - iter 273/395 - loss 0.12078254 - time (sec): 138.34 - samples/sec: 3785.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:36:34,711 epoch 55 - iter 312/395 - loss 0.12105988 - time (sec): 156.88 - samples/sec: 3810.48 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:36:58,147 epoch 55 - iter 351/395 - loss 0.12147335 - time (sec): 180.32 - samples/sec: 3739.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:37:17,190 epoch 55 - iter 390/395 - loss 0.12156761 - time (sec): 199.36 - samples/sec: 3750.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:37:19,398 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:37:19,399 EPOCH 55 done: loss 0.1215 - lr: 0.100000\n",
            "2024-01-22 12:37:19,400  - 1 epochs without improvement\n",
            "2024-01-22 12:37:19,403 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:37:19,404 train mode resetting embeddings\n",
            "2024-01-22 12:37:19,405 train mode resetting embeddings\n",
            "2024-01-22 12:37:38,146 epoch 56 - iter 39/395 - loss 0.11806949 - time (sec): 18.74 - samples/sec: 3981.72 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:37:57,018 epoch 56 - iter 78/395 - loss 0.11609325 - time (sec): 37.61 - samples/sec: 3969.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:38:16,567 epoch 56 - iter 117/395 - loss 0.11804987 - time (sec): 57.16 - samples/sec: 3919.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:38:34,695 epoch 56 - iter 156/395 - loss 0.11908056 - time (sec): 75.29 - samples/sec: 3951.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:38:54,019 epoch 56 - iter 195/395 - loss 0.12032098 - time (sec): 94.61 - samples/sec: 3942.78 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:39:12,717 epoch 56 - iter 234/395 - loss 0.12042907 - time (sec): 113.31 - samples/sec: 3947.62 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:39:34,887 epoch 56 - iter 273/395 - loss 0.11998385 - time (sec): 135.48 - samples/sec: 3856.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:39:53,490 epoch 56 - iter 312/395 - loss 0.12009482 - time (sec): 154.08 - samples/sec: 3872.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:40:14,111 epoch 56 - iter 351/395 - loss 0.11999229 - time (sec): 174.70 - samples/sec: 3850.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:40:35,916 epoch 56 - iter 390/395 - loss 0.12089386 - time (sec): 196.51 - samples/sec: 3805.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:40:38,505 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:40:38,506 EPOCH 56 done: loss 0.1209 - lr: 0.100000\n",
            "2024-01-22 12:40:38,508  - 2 epochs without improvement\n",
            "2024-01-22 12:40:38,510 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:40:38,511 train mode resetting embeddings\n",
            "2024-01-22 12:40:38,513 train mode resetting embeddings\n",
            "2024-01-22 12:40:58,076 epoch 57 - iter 39/395 - loss 0.12106628 - time (sec): 19.56 - samples/sec: 3832.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:41:16,336 epoch 57 - iter 78/395 - loss 0.11784923 - time (sec): 37.82 - samples/sec: 3921.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:41:35,721 epoch 57 - iter 117/395 - loss 0.11985390 - time (sec): 57.21 - samples/sec: 3897.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:41:58,606 epoch 57 - iter 156/395 - loss 0.12019468 - time (sec): 80.09 - samples/sec: 3728.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:42:17,874 epoch 57 - iter 195/395 - loss 0.11964468 - time (sec): 99.36 - samples/sec: 3766.82 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:42:36,249 epoch 57 - iter 234/395 - loss 0.11894655 - time (sec): 117.73 - samples/sec: 3801.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:42:55,899 epoch 57 - iter 273/395 - loss 0.11885815 - time (sec): 137.38 - samples/sec: 3805.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:43:15,179 epoch 57 - iter 312/395 - loss 0.11878339 - time (sec): 156.66 - samples/sec: 3811.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:43:34,732 epoch 57 - iter 351/395 - loss 0.11919620 - time (sec): 176.22 - samples/sec: 3812.78 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:43:56,480 epoch 57 - iter 390/395 - loss 0.11969136 - time (sec): 197.97 - samples/sec: 3778.21 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:43:58,663 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:43:58,664 EPOCH 57 done: loss 0.1197 - lr: 0.100000\n",
            "2024-01-22 12:43:58,665  - 0 epochs without improvement\n",
            "2024-01-22 12:43:58,667 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:43:58,669 train mode resetting embeddings\n",
            "2024-01-22 12:43:58,671 train mode resetting embeddings\n",
            "2024-01-22 12:44:18,119 epoch 58 - iter 39/395 - loss 0.11884180 - time (sec): 19.45 - samples/sec: 3812.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:44:39,822 epoch 58 - iter 78/395 - loss 0.11804835 - time (sec): 41.15 - samples/sec: 3592.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:45:03,080 epoch 58 - iter 117/395 - loss 0.11966358 - time (sec): 64.41 - samples/sec: 3481.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:45:22,507 epoch 58 - iter 156/395 - loss 0.11912657 - time (sec): 83.84 - samples/sec: 3571.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:45:42,505 epoch 58 - iter 195/395 - loss 0.12019833 - time (sec): 103.83 - samples/sec: 3621.82 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:46:01,543 epoch 58 - iter 234/395 - loss 0.12007498 - time (sec): 122.87 - samples/sec: 3670.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:46:20,565 epoch 58 - iter 273/395 - loss 0.12000887 - time (sec): 141.89 - samples/sec: 3702.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:46:39,134 epoch 58 - iter 312/395 - loss 0.12016711 - time (sec): 160.46 - samples/sec: 3737.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:46:57,838 epoch 58 - iter 351/395 - loss 0.12051744 - time (sec): 179.17 - samples/sec: 3756.78 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:47:19,104 epoch 58 - iter 390/395 - loss 0.12005697 - time (sec): 200.43 - samples/sec: 3729.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:47:21,870 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:47:21,871 EPOCH 58 done: loss 0.1201 - lr: 0.100000\n",
            "2024-01-22 12:47:21,873  - 1 epochs without improvement\n",
            "2024-01-22 12:47:21,875 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:47:21,877 train mode resetting embeddings\n",
            "2024-01-22 12:47:21,878 train mode resetting embeddings\n",
            "2024-01-22 12:47:40,747 epoch 59 - iter 39/395 - loss 0.11626262 - time (sec): 18.87 - samples/sec: 3904.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:47:59,107 epoch 59 - iter 78/395 - loss 0.11950659 - time (sec): 37.23 - samples/sec: 3965.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:48:21,209 epoch 59 - iter 117/395 - loss 0.11890118 - time (sec): 59.33 - samples/sec: 3791.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:48:38,976 epoch 59 - iter 156/395 - loss 0.11935051 - time (sec): 77.09 - samples/sec: 3857.23 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:48:58,285 epoch 59 - iter 195/395 - loss 0.12003917 - time (sec): 96.40 - samples/sec: 3876.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:49:19,352 epoch 59 - iter 234/395 - loss 0.11936424 - time (sec): 117.47 - samples/sec: 3824.46 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:49:38,986 epoch 59 - iter 273/395 - loss 0.11944362 - time (sec): 137.10 - samples/sec: 3822.51 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:50:01,411 epoch 59 - iter 312/395 - loss 0.11927932 - time (sec): 159.53 - samples/sec: 3752.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:50:20,316 epoch 59 - iter 351/395 - loss 0.11917760 - time (sec): 178.43 - samples/sec: 3772.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:50:40,026 epoch 59 - iter 390/395 - loss 0.11893230 - time (sec): 198.15 - samples/sec: 3776.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:50:42,250 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:50:42,251 EPOCH 59 done: loss 0.1188 - lr: 0.100000\n",
            "2024-01-22 12:50:42,253  - 0 epochs without improvement\n",
            "2024-01-22 12:50:42,256 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:50:42,257 train mode resetting embeddings\n",
            "2024-01-22 12:50:42,258 train mode resetting embeddings\n",
            "2024-01-22 12:51:00,084 epoch 60 - iter 39/395 - loss 0.11783454 - time (sec): 17.82 - samples/sec: 4079.84 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:51:19,246 epoch 60 - iter 78/395 - loss 0.11820136 - time (sec): 36.99 - samples/sec: 3995.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:51:37,902 epoch 60 - iter 117/395 - loss 0.11881795 - time (sec): 55.64 - samples/sec: 3998.14 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:51:58,086 epoch 60 - iter 156/395 - loss 0.11955988 - time (sec): 75.83 - samples/sec: 3930.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:52:23,588 epoch 60 - iter 195/395 - loss 0.11888405 - time (sec): 101.33 - samples/sec: 3713.67 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:52:42,374 epoch 60 - iter 234/395 - loss 0.11847843 - time (sec): 120.12 - samples/sec: 3747.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:53:01,253 epoch 60 - iter 273/395 - loss 0.11849020 - time (sec): 138.99 - samples/sec: 3766.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:53:21,510 epoch 60 - iter 312/395 - loss 0.11783046 - time (sec): 159.25 - samples/sec: 3764.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:53:40,421 epoch 60 - iter 351/395 - loss 0.11865422 - time (sec): 178.16 - samples/sec: 3782.65 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:54:00,261 epoch 60 - iter 390/395 - loss 0.11871648 - time (sec): 198.00 - samples/sec: 3780.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:54:02,234 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:54:02,235 EPOCH 60 done: loss 0.1188 - lr: 0.100000\n",
            "2024-01-22 12:54:02,237  - 0 epochs without improvement\n",
            "2024-01-22 12:54:02,239 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:54:02,241 train mode resetting embeddings\n",
            "2024-01-22 12:54:02,243 train mode resetting embeddings\n",
            "2024-01-22 12:54:21,671 epoch 61 - iter 39/395 - loss 0.11824211 - time (sec): 19.43 - samples/sec: 3924.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:54:40,286 epoch 61 - iter 78/395 - loss 0.11926255 - time (sec): 38.04 - samples/sec: 3911.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:55:01,568 epoch 61 - iter 117/395 - loss 0.11925699 - time (sec): 59.32 - samples/sec: 3760.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:55:23,178 epoch 61 - iter 156/395 - loss 0.12038463 - time (sec): 80.93 - samples/sec: 3703.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:55:41,898 epoch 61 - iter 195/395 - loss 0.12111189 - time (sec): 99.65 - samples/sec: 3734.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:56:04,890 epoch 61 - iter 234/395 - loss 0.11985504 - time (sec): 122.65 - samples/sec: 3676.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:56:24,452 epoch 61 - iter 273/395 - loss 0.11960978 - time (sec): 142.21 - samples/sec: 3704.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:56:43,015 epoch 61 - iter 312/395 - loss 0.11905192 - time (sec): 160.77 - samples/sec: 3733.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:57:02,724 epoch 61 - iter 351/395 - loss 0.11912834 - time (sec): 180.48 - samples/sec: 3739.99 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:57:20,981 epoch 61 - iter 390/395 - loss 0.11913281 - time (sec): 198.74 - samples/sec: 3764.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:57:23,080 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:57:23,082 EPOCH 61 done: loss 0.1191 - lr: 0.100000\n",
            "2024-01-22 12:57:23,084  - 1 epochs without improvement\n",
            "2024-01-22 12:57:23,086 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 12:57:23,088 train mode resetting embeddings\n",
            "2024-01-22 12:57:23,089 train mode resetting embeddings\n",
            "2024-01-22 12:57:44,672 epoch 62 - iter 39/395 - loss 0.12141931 - time (sec): 21.58 - samples/sec: 3456.01 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:58:06,838 epoch 62 - iter 78/395 - loss 0.11842512 - time (sec): 43.75 - samples/sec: 3449.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:58:26,035 epoch 62 - iter 117/395 - loss 0.11749393 - time (sec): 62.95 - samples/sec: 3606.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:58:44,491 epoch 62 - iter 156/395 - loss 0.11900523 - time (sec): 81.40 - samples/sec: 3698.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:59:03,736 epoch 62 - iter 195/395 - loss 0.11841648 - time (sec): 100.65 - samples/sec: 3724.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:59:24,165 epoch 62 - iter 234/395 - loss 0.11994394 - time (sec): 121.08 - samples/sec: 3717.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 12:59:43,014 epoch 62 - iter 273/395 - loss 0.11884896 - time (sec): 139.92 - samples/sec: 3749.53 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:00:05,547 epoch 62 - iter 312/395 - loss 0.11908173 - time (sec): 162.46 - samples/sec: 3685.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:00:25,406 epoch 62 - iter 351/395 - loss 0.11866537 - time (sec): 182.32 - samples/sec: 3701.38 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:00:44,307 epoch 62 - iter 390/395 - loss 0.11853210 - time (sec): 201.22 - samples/sec: 3716.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:00:46,735 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:00:46,736 EPOCH 62 done: loss 0.1184 - lr: 0.100000\n",
            "2024-01-22 13:00:46,738  - 0 epochs without improvement\n",
            "2024-01-22 13:00:46,740 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:00:46,741 train mode resetting embeddings\n",
            "2024-01-22 13:00:46,742 train mode resetting embeddings\n",
            "2024-01-22 13:01:05,484 epoch 63 - iter 39/395 - loss 0.11241519 - time (sec): 18.74 - samples/sec: 3994.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:01:24,632 epoch 63 - iter 78/395 - loss 0.11633301 - time (sec): 37.89 - samples/sec: 3922.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:01:43,503 epoch 63 - iter 117/395 - loss 0.11711194 - time (sec): 56.76 - samples/sec: 3946.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:02:05,895 epoch 63 - iter 156/395 - loss 0.11828290 - time (sec): 79.15 - samples/sec: 3804.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:02:25,400 epoch 63 - iter 195/395 - loss 0.11753091 - time (sec): 98.66 - samples/sec: 3827.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:02:47,216 epoch 63 - iter 234/395 - loss 0.11747151 - time (sec): 120.47 - samples/sec: 3752.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:03:06,254 epoch 63 - iter 273/395 - loss 0.11765001 - time (sec): 139.51 - samples/sec: 3777.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:03:24,852 epoch 63 - iter 312/395 - loss 0.11714790 - time (sec): 158.11 - samples/sec: 3799.40 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:03:43,320 epoch 63 - iter 351/395 - loss 0.11742176 - time (sec): 176.58 - samples/sec: 3821.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:04:04,370 epoch 63 - iter 390/395 - loss 0.11782560 - time (sec): 197.63 - samples/sec: 3786.61 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:04:06,438 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:04:06,440 EPOCH 63 done: loss 0.1177 - lr: 0.100000\n",
            "2024-01-22 13:04:06,442  - 0 epochs without improvement\n",
            "2024-01-22 13:04:06,444 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:04:06,446 train mode resetting embeddings\n",
            "2024-01-22 13:04:06,447 train mode resetting embeddings\n",
            "2024-01-22 13:04:25,073 epoch 64 - iter 39/395 - loss 0.11908204 - time (sec): 18.62 - samples/sec: 3928.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:04:44,475 epoch 64 - iter 78/395 - loss 0.11839418 - time (sec): 38.03 - samples/sec: 3915.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:05:04,249 epoch 64 - iter 117/395 - loss 0.11757787 - time (sec): 57.80 - samples/sec: 3897.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:05:27,080 epoch 64 - iter 156/395 - loss 0.11828665 - time (sec): 80.63 - samples/sec: 3723.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:05:45,453 epoch 64 - iter 195/395 - loss 0.11834335 - time (sec): 99.00 - samples/sec: 3770.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:06:07,267 epoch 64 - iter 234/395 - loss 0.11727599 - time (sec): 120.82 - samples/sec: 3734.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:06:27,219 epoch 64 - iter 273/395 - loss 0.11715703 - time (sec): 140.77 - samples/sec: 3735.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:06:47,174 epoch 64 - iter 312/395 - loss 0.11681562 - time (sec): 160.73 - samples/sec: 3731.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:07:05,834 epoch 64 - iter 351/395 - loss 0.11716669 - time (sec): 179.38 - samples/sec: 3755.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:07:25,083 epoch 64 - iter 390/395 - loss 0.11778385 - time (sec): 198.63 - samples/sec: 3764.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:07:27,273 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:07:27,276 EPOCH 64 done: loss 0.1178 - lr: 0.100000\n",
            "2024-01-22 13:07:27,278  - 1 epochs without improvement\n",
            "2024-01-22 13:07:27,280 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:07:27,282 train mode resetting embeddings\n",
            "2024-01-22 13:07:27,284 train mode resetting embeddings\n",
            "2024-01-22 13:07:45,718 epoch 65 - iter 39/395 - loss 0.11926518 - time (sec): 18.43 - samples/sec: 3968.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:08:06,731 epoch 65 - iter 78/395 - loss 0.11590612 - time (sec): 39.45 - samples/sec: 3703.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:08:26,316 epoch 65 - iter 117/395 - loss 0.11539114 - time (sec): 59.03 - samples/sec: 3727.66 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:08:44,921 epoch 65 - iter 156/395 - loss 0.11627778 - time (sec): 77.64 - samples/sec: 3781.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:09:04,454 epoch 65 - iter 195/395 - loss 0.11686376 - time (sec): 97.17 - samples/sec: 3792.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:09:25,675 epoch 65 - iter 234/395 - loss 0.11610392 - time (sec): 118.39 - samples/sec: 3766.64 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:09:44,900 epoch 65 - iter 273/395 - loss 0.11655826 - time (sec): 137.61 - samples/sec: 3782.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:10:04,230 epoch 65 - iter 312/395 - loss 0.11699902 - time (sec): 156.95 - samples/sec: 3794.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:10:23,862 epoch 65 - iter 351/395 - loss 0.11694115 - time (sec): 176.58 - samples/sec: 3804.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:10:47,590 epoch 65 - iter 390/395 - loss 0.11710220 - time (sec): 200.31 - samples/sec: 3733.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:10:49,783 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:10:49,785 EPOCH 65 done: loss 0.1171 - lr: 0.100000\n",
            "2024-01-22 13:10:49,787  - 0 epochs without improvement\n",
            "2024-01-22 13:10:49,789 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:10:49,790 train mode resetting embeddings\n",
            "2024-01-22 13:10:49,791 train mode resetting embeddings\n",
            "2024-01-22 13:11:08,458 epoch 66 - iter 39/395 - loss 0.11494938 - time (sec): 18.67 - samples/sec: 3966.99 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:11:26,386 epoch 66 - iter 78/395 - loss 0.11666862 - time (sec): 36.59 - samples/sec: 4018.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:11:44,638 epoch 66 - iter 117/395 - loss 0.11685362 - time (sec): 54.85 - samples/sec: 4030.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:12:03,701 epoch 66 - iter 156/395 - loss 0.11693416 - time (sec): 73.91 - samples/sec: 4009.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:12:23,272 epoch 66 - iter 195/395 - loss 0.11750988 - time (sec): 93.48 - samples/sec: 3962.40 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:12:42,786 epoch 66 - iter 234/395 - loss 0.11735770 - time (sec): 112.99 - samples/sec: 3947.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:13:07,002 epoch 66 - iter 273/395 - loss 0.11697112 - time (sec): 137.21 - samples/sec: 3823.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:13:29,386 epoch 66 - iter 312/395 - loss 0.11622110 - time (sec): 159.59 - samples/sec: 3751.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:13:48,989 epoch 66 - iter 351/395 - loss 0.11646224 - time (sec): 179.20 - samples/sec: 3758.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:14:08,040 epoch 66 - iter 390/395 - loss 0.11590668 - time (sec): 198.25 - samples/sec: 3774.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:14:10,138 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:14:10,140 EPOCH 66 done: loss 0.1158 - lr: 0.100000\n",
            "2024-01-22 13:14:10,141  - 0 epochs without improvement\n",
            "2024-01-22 13:14:10,143 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:14:10,145 train mode resetting embeddings\n",
            "2024-01-22 13:14:10,146 train mode resetting embeddings\n",
            "2024-01-22 13:14:30,077 epoch 67 - iter 39/395 - loss 0.11292553 - time (sec): 19.93 - samples/sec: 3796.90 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:14:48,450 epoch 67 - iter 78/395 - loss 0.11567967 - time (sec): 38.30 - samples/sec: 3904.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:15:06,947 epoch 67 - iter 117/395 - loss 0.11495201 - time (sec): 56.80 - samples/sec: 3938.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:15:25,223 epoch 67 - iter 156/395 - loss 0.11568397 - time (sec): 75.07 - samples/sec: 3957.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:15:44,473 epoch 67 - iter 195/395 - loss 0.11526523 - time (sec): 94.33 - samples/sec: 3933.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:16:07,104 epoch 67 - iter 234/395 - loss 0.11565688 - time (sec): 116.96 - samples/sec: 3822.64 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:16:26,065 epoch 67 - iter 273/395 - loss 0.11552434 - time (sec): 135.92 - samples/sec: 3840.93 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:16:45,994 epoch 67 - iter 312/395 - loss 0.11586673 - time (sec): 155.85 - samples/sec: 3828.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:17:06,360 epoch 67 - iter 351/395 - loss 0.11574407 - time (sec): 176.21 - samples/sec: 3817.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:17:27,209 epoch 67 - iter 390/395 - loss 0.11574637 - time (sec): 197.06 - samples/sec: 3794.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:17:29,734 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:17:29,736 EPOCH 67 done: loss 0.1157 - lr: 0.100000\n",
            "2024-01-22 13:17:29,737  - 0 epochs without improvement\n",
            "2024-01-22 13:17:29,739 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:17:29,741 train mode resetting embeddings\n",
            "2024-01-22 13:17:29,742 train mode resetting embeddings\n",
            "2024-01-22 13:17:49,261 epoch 68 - iter 39/395 - loss 0.12137026 - time (sec): 19.52 - samples/sec: 3817.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:18:08,019 epoch 68 - iter 78/395 - loss 0.11897852 - time (sec): 38.28 - samples/sec: 3884.15 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:18:31,235 epoch 68 - iter 117/395 - loss 0.11675678 - time (sec): 61.49 - samples/sec: 3648.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:18:51,475 epoch 68 - iter 156/395 - loss 0.11684561 - time (sec): 81.73 - samples/sec: 3667.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:19:09,791 epoch 68 - iter 195/395 - loss 0.11576143 - time (sec): 100.05 - samples/sec: 3725.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:19:28,520 epoch 68 - iter 234/395 - loss 0.11566491 - time (sec): 118.78 - samples/sec: 3767.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:19:51,155 epoch 68 - iter 273/395 - loss 0.11569285 - time (sec): 141.41 - samples/sec: 3715.64 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:20:10,139 epoch 68 - iter 312/395 - loss 0.11619892 - time (sec): 160.40 - samples/sec: 3739.58 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:20:29,680 epoch 68 - iter 351/395 - loss 0.11584945 - time (sec): 179.94 - samples/sec: 3746.82 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:20:47,877 epoch 68 - iter 390/395 - loss 0.11603960 - time (sec): 198.13 - samples/sec: 3775.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:20:50,046 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:20:50,047 EPOCH 68 done: loss 0.1161 - lr: 0.100000\n",
            "2024-01-22 13:20:50,049  - 1 epochs without improvement\n",
            "2024-01-22 13:20:50,051 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:20:50,053 train mode resetting embeddings\n",
            "2024-01-22 13:20:50,054 train mode resetting embeddings\n",
            "2024-01-22 13:21:10,842 epoch 69 - iter 39/395 - loss 0.11400151 - time (sec): 20.79 - samples/sec: 3520.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:21:29,702 epoch 69 - iter 78/395 - loss 0.11309752 - time (sec): 39.65 - samples/sec: 3729.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:21:48,919 epoch 69 - iter 117/395 - loss 0.11481030 - time (sec): 58.86 - samples/sec: 3779.83 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:22:09,892 epoch 69 - iter 156/395 - loss 0.11568799 - time (sec): 79.84 - samples/sec: 3742.61 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:22:29,236 epoch 69 - iter 195/395 - loss 0.11631748 - time (sec): 99.18 - samples/sec: 3766.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:22:47,686 epoch 69 - iter 234/395 - loss 0.11612016 - time (sec): 117.63 - samples/sec: 3799.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:23:08,045 epoch 69 - iter 273/395 - loss 0.11542495 - time (sec): 137.99 - samples/sec: 3782.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:23:27,580 epoch 69 - iter 312/395 - loss 0.11618794 - time (sec): 157.52 - samples/sec: 3794.48 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:23:52,480 epoch 69 - iter 351/395 - loss 0.11589615 - time (sec): 182.43 - samples/sec: 3691.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:24:11,527 epoch 69 - iter 390/395 - loss 0.11609285 - time (sec): 201.47 - samples/sec: 3713.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:24:13,476 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:24:13,478 EPOCH 69 done: loss 0.1161 - lr: 0.100000\n",
            "2024-01-22 13:24:13,479  - 2 epochs without improvement\n",
            "2024-01-22 13:24:13,481 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:24:13,482 train mode resetting embeddings\n",
            "2024-01-22 13:24:13,483 train mode resetting embeddings\n",
            "2024-01-22 13:24:32,960 epoch 70 - iter 39/395 - loss 0.11766669 - time (sec): 19.47 - samples/sec: 3809.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:24:51,148 epoch 70 - iter 78/395 - loss 0.11791746 - time (sec): 37.66 - samples/sec: 3935.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:25:12,692 epoch 70 - iter 117/395 - loss 0.11740453 - time (sec): 59.21 - samples/sec: 3788.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:25:31,472 epoch 70 - iter 156/395 - loss 0.11533377 - time (sec): 77.99 - samples/sec: 3819.16 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:25:50,902 epoch 70 - iter 195/395 - loss 0.11652681 - time (sec): 97.42 - samples/sec: 3823.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:26:09,645 epoch 70 - iter 234/395 - loss 0.11551282 - time (sec): 116.16 - samples/sec: 3846.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:26:33,253 epoch 70 - iter 273/395 - loss 0.11516400 - time (sec): 139.77 - samples/sec: 3731.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:26:53,389 epoch 70 - iter 312/395 - loss 0.11534753 - time (sec): 159.90 - samples/sec: 3741.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:27:12,297 epoch 70 - iter 351/395 - loss 0.11556487 - time (sec): 178.81 - samples/sec: 3766.83 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:27:31,688 epoch 70 - iter 390/395 - loss 0.11530361 - time (sec): 198.20 - samples/sec: 3774.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:27:33,826 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:27:33,827 EPOCH 70 done: loss 0.1153 - lr: 0.100000\n",
            "2024-01-22 13:27:33,829  - 0 epochs without improvement\n",
            "2024-01-22 13:27:33,830 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:27:33,832 train mode resetting embeddings\n",
            "2024-01-22 13:27:33,832 train mode resetting embeddings\n",
            "2024-01-22 13:27:55,613 epoch 71 - iter 39/395 - loss 0.11032881 - time (sec): 21.78 - samples/sec: 3496.83 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:28:16,347 epoch 71 - iter 78/395 - loss 0.11317703 - time (sec): 42.51 - samples/sec: 3562.66 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:28:34,863 epoch 71 - iter 117/395 - loss 0.11322318 - time (sec): 61.03 - samples/sec: 3681.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:28:57,168 epoch 71 - iter 156/395 - loss 0.11385769 - time (sec): 83.33 - samples/sec: 3587.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:29:15,637 epoch 71 - iter 195/395 - loss 0.11407476 - time (sec): 101.80 - samples/sec: 3667.46 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:29:35,892 epoch 71 - iter 234/395 - loss 0.11444227 - time (sec): 122.06 - samples/sec: 3688.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:29:54,403 epoch 71 - iter 273/395 - loss 0.11422715 - time (sec): 140.57 - samples/sec: 3726.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:30:14,103 epoch 71 - iter 312/395 - loss 0.11447699 - time (sec): 160.27 - samples/sec: 3744.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:30:33,614 epoch 71 - iter 351/395 - loss 0.11486665 - time (sec): 179.78 - samples/sec: 3747.58 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:30:52,258 epoch 71 - iter 390/395 - loss 0.11553899 - time (sec): 198.42 - samples/sec: 3769.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:30:54,393 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:30:54,395 EPOCH 71 done: loss 0.1157 - lr: 0.100000\n",
            "2024-01-22 13:30:54,396  - 1 epochs without improvement\n",
            "2024-01-22 13:30:54,398 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:30:54,399 train mode resetting embeddings\n",
            "2024-01-22 13:30:54,402 train mode resetting embeddings\n",
            "2024-01-22 13:31:14,039 epoch 72 - iter 39/395 - loss 0.11406402 - time (sec): 19.64 - samples/sec: 3834.58 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:31:35,561 epoch 72 - iter 78/395 - loss 0.11547482 - time (sec): 41.16 - samples/sec: 3642.04 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:31:54,697 epoch 72 - iter 117/395 - loss 0.11532109 - time (sec): 60.29 - samples/sec: 3721.61 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:32:13,630 epoch 72 - iter 156/395 - loss 0.11405518 - time (sec): 79.23 - samples/sec: 3771.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:32:32,568 epoch 72 - iter 195/395 - loss 0.11390939 - time (sec): 98.17 - samples/sec: 3802.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:32:51,157 epoch 72 - iter 234/395 - loss 0.11484326 - time (sec): 116.75 - samples/sec: 3830.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:33:13,623 epoch 72 - iter 273/395 - loss 0.11447526 - time (sec): 139.22 - samples/sec: 3761.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:33:31,780 epoch 72 - iter 312/395 - loss 0.11454710 - time (sec): 157.38 - samples/sec: 3791.40 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:33:51,125 epoch 72 - iter 351/395 - loss 0.11462218 - time (sec): 176.72 - samples/sec: 3799.51 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:34:15,447 epoch 72 - iter 390/395 - loss 0.11523339 - time (sec): 201.04 - samples/sec: 3721.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:34:17,494 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:34:17,496 EPOCH 72 done: loss 0.1151 - lr: 0.100000\n",
            "2024-01-22 13:34:17,498  - 0 epochs without improvement\n",
            "2024-01-22 13:34:17,500 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:34:17,501 train mode resetting embeddings\n",
            "2024-01-22 13:34:17,503 train mode resetting embeddings\n",
            "2024-01-22 13:34:39,413 epoch 73 - iter 39/395 - loss 0.10736408 - time (sec): 21.91 - samples/sec: 3444.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:34:59,313 epoch 73 - iter 78/395 - loss 0.10828871 - time (sec): 41.81 - samples/sec: 3586.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:35:17,579 epoch 73 - iter 117/395 - loss 0.11123207 - time (sec): 60.08 - samples/sec: 3715.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:35:37,240 epoch 73 - iter 156/395 - loss 0.11113346 - time (sec): 79.74 - samples/sec: 3742.15 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:35:56,558 epoch 73 - iter 195/395 - loss 0.11166766 - time (sec): 99.05 - samples/sec: 3763.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:36:16,946 epoch 73 - iter 234/395 - loss 0.11269157 - time (sec): 119.44 - samples/sec: 3772.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:36:36,384 epoch 73 - iter 273/395 - loss 0.11377067 - time (sec): 138.88 - samples/sec: 3788.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:36:57,581 epoch 73 - iter 312/395 - loss 0.11435515 - time (sec): 160.08 - samples/sec: 3748.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:37:16,038 epoch 73 - iter 351/395 - loss 0.11438810 - time (sec): 178.53 - samples/sec: 3769.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:37:35,690 epoch 73 - iter 390/395 - loss 0.11467077 - time (sec): 198.19 - samples/sec: 3774.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:37:37,761 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:37:37,763 EPOCH 73 done: loss 0.1147 - lr: 0.100000\n",
            "2024-01-22 13:37:37,765  - 0 epochs without improvement\n",
            "2024-01-22 13:37:37,768 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:37:37,769 train mode resetting embeddings\n",
            "2024-01-22 13:37:37,771 train mode resetting embeddings\n",
            "2024-01-22 13:37:57,515 epoch 74 - iter 39/395 - loss 0.11652054 - time (sec): 19.74 - samples/sec: 3793.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:38:16,321 epoch 74 - iter 78/395 - loss 0.11713361 - time (sec): 38.55 - samples/sec: 3902.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:38:35,344 epoch 74 - iter 117/395 - loss 0.11489694 - time (sec): 57.57 - samples/sec: 3897.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:38:56,551 epoch 74 - iter 156/395 - loss 0.11603214 - time (sec): 78.78 - samples/sec: 3796.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:39:18,783 epoch 74 - iter 195/395 - loss 0.11525954 - time (sec): 101.01 - samples/sec: 3733.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:39:39,802 epoch 74 - iter 234/395 - loss 0.11562755 - time (sec): 122.03 - samples/sec: 3686.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:39:58,604 epoch 74 - iter 273/395 - loss 0.11533286 - time (sec): 140.83 - samples/sec: 3712.44 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:40:17,089 epoch 74 - iter 312/395 - loss 0.11508442 - time (sec): 159.32 - samples/sec: 3744.90 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:40:36,522 epoch 74 - iter 351/395 - loss 0.11450682 - time (sec): 178.75 - samples/sec: 3758.15 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:40:56,100 epoch 74 - iter 390/395 - loss 0.11450111 - time (sec): 198.33 - samples/sec: 3772.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:40:58,303 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:40:58,305 EPOCH 74 done: loss 0.1145 - lr: 0.100000\n",
            "2024-01-22 13:40:58,307  - 0 epochs without improvement\n",
            "2024-01-22 13:40:58,309 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:40:58,311 train mode resetting embeddings\n",
            "2024-01-22 13:40:58,312 train mode resetting embeddings\n",
            "2024-01-22 13:41:19,919 epoch 75 - iter 39/395 - loss 0.11152222 - time (sec): 21.61 - samples/sec: 3507.66 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:41:41,942 epoch 75 - iter 78/395 - loss 0.11295379 - time (sec): 43.63 - samples/sec: 3438.85 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:42:00,844 epoch 75 - iter 117/395 - loss 0.11189932 - time (sec): 62.53 - samples/sec: 3589.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:42:22,468 epoch 75 - iter 156/395 - loss 0.11260562 - time (sec): 84.15 - samples/sec: 3558.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:42:41,322 epoch 75 - iter 195/395 - loss 0.11332275 - time (sec): 103.01 - samples/sec: 3626.96 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:43:02,066 epoch 75 - iter 234/395 - loss 0.11376059 - time (sec): 123.75 - samples/sec: 3635.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:43:20,926 epoch 75 - iter 273/395 - loss 0.11367922 - time (sec): 142.61 - samples/sec: 3675.29 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:43:40,650 epoch 75 - iter 312/395 - loss 0.11400335 - time (sec): 162.34 - samples/sec: 3698.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:43:58,672 epoch 75 - iter 351/395 - loss 0.11401602 - time (sec): 180.36 - samples/sec: 3736.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:44:17,191 epoch 75 - iter 390/395 - loss 0.11455812 - time (sec): 198.88 - samples/sec: 3760.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:44:19,446 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:44:19,447 EPOCH 75 done: loss 0.1144 - lr: 0.100000\n",
            "2024-01-22 13:44:19,449  - 0 epochs without improvement\n",
            "2024-01-22 13:44:19,451 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:44:19,452 train mode resetting embeddings\n",
            "2024-01-22 13:44:19,453 train mode resetting embeddings\n",
            "2024-01-22 13:44:38,325 epoch 76 - iter 39/395 - loss 0.10996693 - time (sec): 18.87 - samples/sec: 3960.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:44:59,860 epoch 76 - iter 78/395 - loss 0.11300922 - time (sec): 40.40 - samples/sec: 3694.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:45:19,539 epoch 76 - iter 117/395 - loss 0.11245665 - time (sec): 60.08 - samples/sec: 3733.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:45:38,330 epoch 76 - iter 156/395 - loss 0.11241385 - time (sec): 78.87 - samples/sec: 3780.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:45:57,330 epoch 76 - iter 195/395 - loss 0.11393299 - time (sec): 97.87 - samples/sec: 3808.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:46:16,437 epoch 76 - iter 234/395 - loss 0.11418993 - time (sec): 116.98 - samples/sec: 3826.60 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:46:36,097 epoch 76 - iter 273/395 - loss 0.11415519 - time (sec): 136.64 - samples/sec: 3822.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:46:57,741 epoch 76 - iter 312/395 - loss 0.11420496 - time (sec): 158.28 - samples/sec: 3784.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:47:18,701 epoch 76 - iter 351/395 - loss 0.11419788 - time (sec): 179.25 - samples/sec: 3767.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:47:40,176 epoch 76 - iter 390/395 - loss 0.11437896 - time (sec): 200.72 - samples/sec: 3727.39 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:47:42,396 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:47:42,398 EPOCH 76 done: loss 0.1143 - lr: 0.100000\n",
            "2024-01-22 13:47:42,399  - 0 epochs without improvement\n",
            "2024-01-22 13:47:42,401 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:47:42,403 train mode resetting embeddings\n",
            "2024-01-22 13:47:42,404 train mode resetting embeddings\n",
            "2024-01-22 13:48:02,006 epoch 77 - iter 39/395 - loss 0.11223578 - time (sec): 19.60 - samples/sec: 3825.54 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:48:22,689 epoch 77 - iter 78/395 - loss 0.11322039 - time (sec): 40.28 - samples/sec: 3729.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:48:45,021 epoch 77 - iter 117/395 - loss 0.11423078 - time (sec): 62.62 - samples/sec: 3654.84 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:49:05,495 epoch 77 - iter 156/395 - loss 0.11216192 - time (sec): 83.09 - samples/sec: 3665.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:49:25,089 epoch 77 - iter 195/395 - loss 0.11220427 - time (sec): 102.68 - samples/sec: 3685.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:49:44,107 epoch 77 - iter 234/395 - loss 0.11245932 - time (sec): 121.70 - samples/sec: 3720.32 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:50:06,973 epoch 77 - iter 273/395 - loss 0.11188401 - time (sec): 144.57 - samples/sec: 3639.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:50:25,906 epoch 77 - iter 312/395 - loss 0.11146478 - time (sec): 163.50 - samples/sec: 3672.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:50:44,190 epoch 77 - iter 351/395 - loss 0.11218008 - time (sec): 181.79 - samples/sec: 3708.57 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:51:02,439 epoch 77 - iter 390/395 - loss 0.11269332 - time (sec): 200.03 - samples/sec: 3738.66 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:51:04,558 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:51:04,560 EPOCH 77 done: loss 0.1127 - lr: 0.100000\n",
            "2024-01-22 13:51:04,561  - 0 epochs without improvement\n",
            "2024-01-22 13:51:04,564 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:51:04,565 train mode resetting embeddings\n",
            "2024-01-22 13:51:04,566 train mode resetting embeddings\n",
            "2024-01-22 13:51:24,418 epoch 78 - iter 39/395 - loss 0.11101278 - time (sec): 19.85 - samples/sec: 3849.53 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:51:42,927 epoch 78 - iter 78/395 - loss 0.11353333 - time (sec): 38.36 - samples/sec: 3909.37 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:52:01,742 epoch 78 - iter 117/395 - loss 0.11351865 - time (sec): 57.17 - samples/sec: 3903.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:52:23,168 epoch 78 - iter 156/395 - loss 0.11279612 - time (sec): 78.60 - samples/sec: 3792.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:52:44,891 epoch 78 - iter 195/395 - loss 0.11444703 - time (sec): 100.32 - samples/sec: 3722.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:53:03,752 epoch 78 - iter 234/395 - loss 0.11434022 - time (sec): 119.18 - samples/sec: 3756.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:53:24,643 epoch 78 - iter 273/395 - loss 0.11428163 - time (sec): 140.08 - samples/sec: 3739.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:53:43,099 epoch 78 - iter 312/395 - loss 0.11424790 - time (sec): 158.53 - samples/sec: 3766.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:54:04,566 epoch 78 - iter 351/395 - loss 0.11414110 - time (sec): 180.00 - samples/sec: 3744.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:54:24,660 epoch 78 - iter 390/395 - loss 0.11415482 - time (sec): 200.09 - samples/sec: 3740.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:54:26,721 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:54:26,722 EPOCH 78 done: loss 0.1143 - lr: 0.100000\n",
            "2024-01-22 13:54:26,724  - 1 epochs without improvement\n",
            "2024-01-22 13:54:26,726 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:54:26,727 train mode resetting embeddings\n",
            "2024-01-22 13:54:26,729 train mode resetting embeddings\n",
            "2024-01-22 13:54:49,535 epoch 79 - iter 39/395 - loss 0.11039429 - time (sec): 22.81 - samples/sec: 3432.38 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:55:08,445 epoch 79 - iter 78/395 - loss 0.11369864 - time (sec): 41.72 - samples/sec: 3638.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:55:29,855 epoch 79 - iter 117/395 - loss 0.11306083 - time (sec): 63.13 - samples/sec: 3593.06 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:55:49,338 epoch 79 - iter 156/395 - loss 0.11336516 - time (sec): 82.61 - samples/sec: 3660.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:56:07,882 epoch 79 - iter 195/395 - loss 0.11318723 - time (sec): 101.15 - samples/sec: 3722.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:56:27,395 epoch 79 - iter 234/395 - loss 0.11302016 - time (sec): 120.67 - samples/sec: 3738.07 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:56:46,670 epoch 79 - iter 273/395 - loss 0.11317411 - time (sec): 139.94 - samples/sec: 3751.10 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:57:05,383 epoch 79 - iter 312/395 - loss 0.11353284 - time (sec): 158.65 - samples/sec: 3776.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:57:24,686 epoch 79 - iter 351/395 - loss 0.11364483 - time (sec): 177.96 - samples/sec: 3783.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:57:43,609 epoch 79 - iter 390/395 - loss 0.11392838 - time (sec): 196.88 - samples/sec: 3799.39 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:57:45,631 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:57:45,632 EPOCH 79 done: loss 0.1138 - lr: 0.100000\n",
            "2024-01-22 13:57:45,635  - 2 epochs without improvement\n",
            "2024-01-22 13:57:45,636 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 13:57:45,638 train mode resetting embeddings\n",
            "2024-01-22 13:57:45,639 train mode resetting embeddings\n",
            "2024-01-22 13:58:06,998 epoch 80 - iter 39/395 - loss 0.11218618 - time (sec): 21.36 - samples/sec: 3452.72 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:58:25,233 epoch 80 - iter 78/395 - loss 0.11267269 - time (sec): 39.59 - samples/sec: 3731.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:58:44,371 epoch 80 - iter 117/395 - loss 0.11093527 - time (sec): 58.73 - samples/sec: 3789.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:59:03,734 epoch 80 - iter 156/395 - loss 0.11179290 - time (sec): 78.09 - samples/sec: 3813.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:59:22,157 epoch 80 - iter 195/395 - loss 0.11187198 - time (sec): 96.52 - samples/sec: 3838.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 13:59:43,300 epoch 80 - iter 234/395 - loss 0.11147262 - time (sec): 117.66 - samples/sec: 3800.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:00:03,841 epoch 80 - iter 273/395 - loss 0.11162959 - time (sec): 138.20 - samples/sec: 3782.66 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:00:25,097 epoch 80 - iter 312/395 - loss 0.11178408 - time (sec): 159.46 - samples/sec: 3746.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:00:46,424 epoch 80 - iter 351/395 - loss 0.11174578 - time (sec): 180.78 - samples/sec: 3726.76 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:01:05,801 epoch 80 - iter 390/395 - loss 0.11211569 - time (sec): 200.16 - samples/sec: 3737.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:01:07,989 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:01:07,990 EPOCH 80 done: loss 0.1121 - lr: 0.100000\n",
            "2024-01-22 14:01:07,993  - 0 epochs without improvement\n",
            "2024-01-22 14:01:07,995 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:01:07,997 train mode resetting embeddings\n",
            "2024-01-22 14:01:07,998 train mode resetting embeddings\n",
            "2024-01-22 14:01:28,512 epoch 81 - iter 39/395 - loss 0.11371465 - time (sec): 20.51 - samples/sec: 3716.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:01:51,032 epoch 81 - iter 78/395 - loss 0.11159509 - time (sec): 43.03 - samples/sec: 3534.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:02:09,630 epoch 81 - iter 117/395 - loss 0.11029371 - time (sec): 61.63 - samples/sec: 3666.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:02:29,637 epoch 81 - iter 156/395 - loss 0.11181720 - time (sec): 81.64 - samples/sec: 3682.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:02:49,620 epoch 81 - iter 195/395 - loss 0.11030409 - time (sec): 101.62 - samples/sec: 3691.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:03:12,129 epoch 81 - iter 234/395 - loss 0.11119888 - time (sec): 124.13 - samples/sec: 3628.34 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:03:31,765 epoch 81 - iter 273/395 - loss 0.11147577 - time (sec): 143.77 - samples/sec: 3651.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:03:50,200 epoch 81 - iter 312/395 - loss 0.11157738 - time (sec): 162.20 - samples/sec: 3699.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:04:09,081 epoch 81 - iter 351/395 - loss 0.11246644 - time (sec): 181.08 - samples/sec: 3717.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:04:28,181 epoch 81 - iter 390/395 - loss 0.11183700 - time (sec): 200.18 - samples/sec: 3737.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:04:30,379 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:04:30,380 EPOCH 81 done: loss 0.1119 - lr: 0.100000\n",
            "2024-01-22 14:04:30,382  - 0 epochs without improvement\n",
            "2024-01-22 14:04:30,384 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:04:30,385 train mode resetting embeddings\n",
            "2024-01-22 14:04:30,387 train mode resetting embeddings\n",
            "2024-01-22 14:04:48,742 epoch 82 - iter 39/395 - loss 0.10736396 - time (sec): 18.35 - samples/sec: 4046.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:05:08,319 epoch 82 - iter 78/395 - loss 0.10855564 - time (sec): 37.93 - samples/sec: 3915.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:05:27,103 epoch 82 - iter 117/395 - loss 0.10786497 - time (sec): 56.72 - samples/sec: 3925.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:05:50,138 epoch 82 - iter 156/395 - loss 0.10746116 - time (sec): 79.75 - samples/sec: 3723.77 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:06:10,381 epoch 82 - iter 195/395 - loss 0.10837955 - time (sec): 99.99 - samples/sec: 3732.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:06:28,914 epoch 82 - iter 234/395 - loss 0.10846745 - time (sec): 118.53 - samples/sec: 3762.65 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:06:50,919 epoch 82 - iter 273/395 - loss 0.10919647 - time (sec): 140.53 - samples/sec: 3720.64 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:07:09,587 epoch 82 - iter 312/395 - loss 0.10998703 - time (sec): 159.20 - samples/sec: 3755.65 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:07:29,783 epoch 82 - iter 351/395 - loss 0.11043657 - time (sec): 179.39 - samples/sec: 3754.86 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:07:48,417 epoch 82 - iter 390/395 - loss 0.11010340 - time (sec): 198.03 - samples/sec: 3777.38 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:07:50,543 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:07:50,545 EPOCH 82 done: loss 0.1100 - lr: 0.100000\n",
            "2024-01-22 14:07:50,546  - 0 epochs without improvement\n",
            "2024-01-22 14:07:50,548 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:07:50,550 train mode resetting embeddings\n",
            "2024-01-22 14:07:50,551 train mode resetting embeddings\n",
            "2024-01-22 14:08:09,390 epoch 83 - iter 39/395 - loss 0.10989565 - time (sec): 18.84 - samples/sec: 3861.47 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:08:32,070 epoch 83 - iter 78/395 - loss 0.10870413 - time (sec): 41.52 - samples/sec: 3577.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:08:50,407 epoch 83 - iter 117/395 - loss 0.10987075 - time (sec): 59.85 - samples/sec: 3704.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:09:09,637 epoch 83 - iter 156/395 - loss 0.11056203 - time (sec): 79.08 - samples/sec: 3744.87 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:09:29,755 epoch 83 - iter 195/395 - loss 0.10991251 - time (sec): 99.20 - samples/sec: 3733.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:09:49,489 epoch 83 - iter 234/395 - loss 0.11061360 - time (sec): 118.94 - samples/sec: 3749.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:10:08,815 epoch 83 - iter 273/395 - loss 0.11090030 - time (sec): 138.26 - samples/sec: 3770.31 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:10:27,748 epoch 83 - iter 312/395 - loss 0.11101425 - time (sec): 157.20 - samples/sec: 3793.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:10:46,664 epoch 83 - iter 351/395 - loss 0.11099015 - time (sec): 176.11 - samples/sec: 3812.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:11:08,960 epoch 83 - iter 390/395 - loss 0.11074051 - time (sec): 198.41 - samples/sec: 3761.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:11:14,108 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:11:14,110 EPOCH 83 done: loss 0.1108 - lr: 0.100000\n",
            "2024-01-22 14:11:14,111  - 1 epochs without improvement\n",
            "2024-01-22 14:11:14,113 ----------------------------------------------------------------------------------------------------\n",
            "2024-01-22 14:11:14,115 train mode resetting embeddings\n",
            "2024-01-22 14:11:14,115 train mode resetting embeddings\n",
            "2024-01-22 14:11:33,241 epoch 84 - iter 39/395 - loss 0.11217137 - time (sec): 19.12 - samples/sec: 3913.79 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:11:55,018 epoch 84 - iter 78/395 - loss 0.10886064 - time (sec): 40.90 - samples/sec: 3698.54 - lr: 0.100000 - momentum: 0.000000\n",
            "2024-01-22 14:12:14,037 epoch 84 - iter 117/395 - loss 0.10935103 - time (sec): 59.92 - samples/sec: 3778.34 - lr: 0.100000 - momentum: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "model_path = 'resources/taggers/example-ner/final-model.pt'\n",
        "drive_path = '/content/drive/My Drive/models/flair/50-epoch/final-model.pt'\n",
        "drive_dir = os.path.dirname(drive_path)\n",
        "if not os.path.exists(drive_dir):\n",
        "    os.makedirs(drive_dir)\n",
        "shutil.copy(model_path, drive_path)\n"
      ],
      "metadata": {
        "id": "glZcXKtV8cOQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}